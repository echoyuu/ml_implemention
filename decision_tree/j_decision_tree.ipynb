{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习实战-决策树"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "定义：分类决策树模型是一种描述对实例进行分类的树形结构。决策树由节点（node）和有向边（directed edge）组成。节点有两种类型：内部结点和叶结点，内部结点表示一个特征或者属性，叶结点表示一个类。\n",
    "\n",
    "用决策树进行分类，从根结点开始，对实例的某一特征进行测试，根据测试结构，将实例分配到其子结点；这时，每一个子结点对用着特征的一个取值，如此递归的对实例进行测试并分配，直至到达叶结点。最后将实例分到叶结点的类中。\n",
    "\n",
    "分而治之 divide-and-conquer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "决策树学习基本算法\n",
    "\n",
    "输入：训练集 D = {(x1,y1),(x2,y2)````(xm,ym)};\n",
    "     属性集 A = {a1, a2,`````,ad}.\n",
    "过程：函数TreeGenerate(D,A)\n",
    "1.生产节点node；\n",
    "2.if D中样本全属于同一类别C then\n",
    "3.   将node标记为C类叶节点；return\n",
    "4.end if\n",
    "5.if A=null OR D中样本在A上取值相同 then\n",
    "6.   将node标记为叶节点，其类别标记为D中样本数最多的类；then\n",
    "7.end if\n",
    "8.从A中选择最优划分属性a*；\n",
    "9.for a*的每一个值av* do\n",
    "10.   为node生成一个分之；令Dv表示D中在a*上取值为av*的样本子集\n",
    "11.   if Dv为空 then\n",
    "12.      将分支结点标记为叶结点，其类别标记为D中样本最多的类；return\n",
    "13.   else\n",
    "14.      以 TreeGenerate(Dv, A\\{a*})为分支结点\n",
    "15.   end if\n",
    "16.end if\n",
    "输出：以node为根结点的一棵决策树"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "叶节点的产生条件\n",
    "1.当前结点包含的样本全属于同一类别，无需划分\n",
    "2.当前属性集为空，或是所有样本在属性上取值相同，无法划分\n",
    "3.当前结点包含的样本集合为空，不能划分"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ID3 算法原理和实现\n",
    "信息增益\n",
    "熵"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "决策树的一般流程： \n",
    "(1)收集数据：可以使用任何方法。 \n",
    "(2)准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。 \n",
    "(3)分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。 \n",
    "(4)训练算法：构造树的数据结构。 \n",
    "(5)测试算法：使用经验树计算错误率。 \n",
    "(6)使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据 \n",
    "的内在含义。 \n",
    "目前常用的决策树算法有ID3算法、改进的C4.5算法和CART算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.首先创建一个数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T02:31:02.014158Z",
     "start_time": "2018-07-24T02:31:02.001517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator\n",
    "#import treePlotter\n",
    "#创建数据集\n",
    "\n",
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfing ', 'flippers']\n",
    "    #change to discrete values\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "【二】做数据集转换\n",
    "本文中我没有使用作者所提供的鱼的数据集，而是采用了UCI的机器学习数据集中的汽车评价数据集（http://archive.ics.uci.edu/ml/datasets/Car+Evaluation），里面有很多很好的数据集，建议做机器学习的同学多使用里面的数据。而UCI的数据集大部分都是txt格式的，所以写了段讲txt格式转换为矩阵的额外的代码。\n",
    "https://blog.csdn.net/cxjoker/article/details/79501887\n",
    "这段代码整体上比较简单，主要是用了readlines读取文本并且使用split对文本进行分割形成数据矩阵即可。\n",
    "\"\"\"\n",
    "def file2matrix(filename):\n",
    "    fr=open(filename)\n",
    "    lists=fr.readlines()\n",
    "    listnum=[]\n",
    "    for k in lists:\n",
    "        listnum.append(k.strip().split(','))  \n",
    "    return listnum\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T00:35:09.088878Z",
     "start_time": "2018-07-23T00:35:09.077439Z"
    }
   },
   "source": [
    "d = {'a':3,'b':4}\n",
    "for v in d.values():\n",
    "    print(v)\n",
    "for k in d.keys():\n",
    "    print(k)\n",
    "for k, v in d.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.计算香农熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码主要是用于计算数据的每个特征信息熵，信息熵用于描述数据的混乱程度，信息熵越大说明数据包含的信息越多，也就是数据的波动越大。\n",
    "\n",
    "而ID3算法采用的是信息增益作为计算指标来评价每个特征所包含的信息的多少，而信息增益方法对可取数值较多的特征有所偏好，即本身可取数值较多的特征本身就包含更多的信息，为了减少这种偏好，又有C4.5和CART树，C4.5用信息增益率来衡量数据特征，从而摒除了这种偏好；CART树使用了“基尼指数”来衡量特征，基尼指数越小说明他的数据纯度就越高，选取特征时选取划分后使基尼指数最小的特征作为划分标准，即选取特征后使数据集变得更加纯，从而减少了数据集本身的混乱程度，本身决策树做的事情就是这个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T02:31:05.729212Z",
     "start_time": "2018-07-24T02:31:05.716229Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#这段代码主要用于计算数据的每个特征信息熵，信息熵用于描述数据的混乱程度，信息熵越大说明数据包含的信息越多，也就是数据的波动越大\n",
    "from math import log\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for fectVec in dataSet:\n",
    "        currentLabel = fectVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for value in labelCounts.values():\n",
    "        prob = float(value )/ numEntries\n",
    "        shannonEnt -= prob*log(prob, 2)\n",
    "    return shannonEnt  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T08:15:46.260712Z",
     "start_time": "2018-07-21T08:15:46.248140Z"
    },
    "collapsed": true
   },
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for value in labelCounts.values():\n",
    "        prob = float(value)/numEntries\n",
    "        shannonEnt -= prob*log(prob, 2)\n",
    "    return shannonEnt\n",
    "#calcShannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-22T23:54:55.320394Z",
     "start_time": "2018-07-22T23:54:55.300861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat, labels =createDataSet()\n",
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T00:42:00.354497Z",
     "start_time": "2018-07-23T00:42:00.338230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] \n",
      " ['no surfing ', 'flippers']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "print(myDat,'\\n',labels)\n",
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T08:15:30.861840Z",
     "start_time": "2018-07-21T08:15:30.842312Z"
    },
    "collapsed": true
   },
   "source": [
    "def calcShannonEnt(dataSet):   \n",
    "    numEntries = len(dataSet) #compute length of dataSet \n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:#迭代出每行数据\n",
    "        currentLabel = featVec[-1] # currentLabel赋值每行数据的类别标签，无法保存值\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0 #若没有该键，则使用字典的自动添加进行添加值为0的项，取0是因为下一行代码 \n",
    "        labelCounts[currentLabel] += 1 #对currentlabel计数，每有一个key：currentlabel，就在对应的key的值上加一\n",
    "    shannonEnt = 0.0 \n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries  \n",
    "        shannonEnt -= prob*log(prob, 2) # log base 2\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T01:41:57.198759Z",
     "start_time": "2018-07-18T01:41:57.185385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] \n",
      " ['no surfing ', 'flippers']\n",
      "0.9709505944546686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nnumEntries 5\\ncurrentLabel yes\\nlabelCounts[currentLabel] 0\\nlabelCounts[currentLabel] 1\\nlabelCounts {'yes': 1}\\ncurrentLabel yes\\nlabelCounts[currentLabel] 2\\nlabelCounts {'yes': 2}\\ncurrentLabel no\\nlabelCounts[currentLabel] 0\\nlabelCounts[currentLabel] 1\\nlabelCounts {'yes': 2, 'no': 1}\\ncurrentLabel no\\nlabelCounts[currentLabel] 2\\nlabelCounts {'yes': 2, 'no': 2}\\ncurrentLabel no\\nlabelCounts[currentLabel] 3\\nlabelCounts {'yes': 2, 'no': 3}\\n0.9709505944546686\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "print(myDat,'\\n',labels)\n",
    "\n",
    "calcShannonEnt(myDat)\n",
    "print(calcShannonEnt(myDat))\n",
    "'''\n",
    "numEntries 5\n",
    "currentLabel yes\n",
    "labelCounts[currentLabel] 0\n",
    "labelCounts[currentLabel] 1\n",
    "labelCounts {'yes': 1}\n",
    "currentLabel yes\n",
    "labelCounts[currentLabel] 2\n",
    "labelCounts {'yes': 2}\n",
    "currentLabel no\n",
    "labelCounts[currentLabel] 0\n",
    "labelCounts[currentLabel] 1\n",
    "labelCounts {'yes': 2, 'no': 1}\n",
    "currentLabel no\n",
    "labelCounts[currentLabel] 2\n",
    "labelCounts {'yes': 2, 'no': 2}\n",
    "currentLabel no\n",
    "labelCounts[currentLabel] 3\n",
    "labelCounts {'yes': 2, 'no': 3}\n",
    "0.9709505944546686\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T01:43:22.568495Z",
     "start_time": "2018-07-18T01:43:22.559996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] ['no surfing ', 'flippers']\n",
      "Ent changed: 1.3709505944546687\n"
     ]
    }
   ],
   "source": [
    "myDat[0][-1] ='maybe'\n",
    "print(myDat, labels)\n",
    "print('Ent changed:', calcShannonEnt(myDat))\n",
    "#可以看出，在myDat[0][-1]更改之后，熵变大了。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T00:52:31.570841Z",
     "start_time": "2018-07-23T00:52:31.562853Z"
    }
   },
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for fectVec in dataSet:\n",
    "        if fectVec[axis] == value:\n",
    "            reducedFectVec = fectVec[:axis]\n",
    "            reducedFectVec.extend(fectVec[axis+1:])\n",
    "        retDataSet.append(reducedFectVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T00:52:32.404726Z",
     "start_time": "2018-07-23T00:52:32.398031Z"
    }
   },
   "source": [
    "myDat, label = createDataSet()\n",
    "splitDataSet(myDat, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.分离数据"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "度量数据集的无序程度，分类算法除了需要测量信息熵，还需要划分数据集，度量划分数据集的熵，以便判断当前是否正确地划分了数据集\n",
    "将对每个特征划分数据集结果计算一次信息熵，然后判断按照哪个数据集是最好的划分方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T02:31:14.161239Z",
     "start_time": "2018-07-24T02:31:14.153134Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T00:53:53.179308Z",
     "start_time": "2018-07-23T00:53:53.168682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat, label = createDataSet()\n",
    "splitDataSet(myDat, 1, 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T08:32:35.188786Z",
     "start_time": "2018-07-21T08:32:35.179740Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "source": [
    "# 分离数据\n",
    "def splitDataSet(dataSet, axis, value): \n",
    "    #待划分的数据集、划分数据集的特征、需要返回的特征的值\n",
    "    retDataSet = [] #创建新的list对象\n",
    "    for featVec in dataSet: \n",
    "        \"\"\"数据集这个列表中的各个元素也是列表，要遍历数据集中每个元素，\n",
    "        一旦发现符合要求的值，则将其添加到新创建的列表中\n",
    "        \"\"\"\n",
    "        if featVec[axis] == value: #判断axis列的值是否为value，程序将符合特征的数据抽取出来\n",
    "            reducedFeatVec = featVec[:axis] # [:axis]表示前axis列，即若axis为2，就是取featVec的前axis列  print('1reducedFeatVec', reducedFeatVec)\n",
    "            reducedFeatVec.extend(featVec[axis+1:]) # [axis+1:]表示从跳过axis+1行，取接下来的数据 print('2reducedFeatVec', reducedFeatVec)\n",
    "            retDataSet.append(reducedFeatVec) # 列表扩展 print('3retDataSet', retDataSet)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T08:32:40.486579Z",
     "start_time": "2018-07-21T08:32:40.474198Z"
    }
   },
   "source": [
    "myDat, label = createDataSet()\n",
    "splitDataSet(myDat, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T02:16:22.831403Z",
     "start_time": "2018-07-18T02:16:22.802177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1reducedFeatVec [1]\n",
      "2reducedFeatVec [1, 'yes']\n",
      "3retDataSet [[1, 'yes']]\n",
      "1reducedFeatVec [1]\n",
      "2reducedFeatVec [1, 'yes']\n",
      "3retDataSet [[1, 'yes'], [1, 'yes']]\n",
      "1reducedFeatVec [0]\n",
      "2reducedFeatVec [0, 'no']\n",
      "3retDataSet [[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "1reducedFeatVec [0]\n",
      "2reducedFeatVec [0, 'no']\n",
      "3retDataSet [[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat, label = createDataSet()\n",
    "splitDataSet(myDat, 1, 1)\n",
    "\"\"\"\n",
    "1reducedFeatVec [1]\n",
    "2reducedFeatVec [1, 'yes']\n",
    "3retDataSet [[1, 'yes']]\n",
    "1reducedFeatVec [1]\n",
    "2reducedFeatVec [1, 'yes']\n",
    "3retDataSet [[1, 'yes'], [1, 'yes']]\n",
    "1reducedFeatVec [0]\n",
    "2reducedFeatVec [0, 'no']\n",
    "3retDataSet [[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
    "1reducedFeatVec [0]\n",
    "2reducedFeatVec [0, 'no']\n",
    "3retDataSet [[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]\n",
    "以axis = 1为基准即第二列，删除了value ！= 1的数据，并重新组合。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "此段代码中用到了extend函数和append函数，都是做数据连接的，但是主要区别是append函数直接将连接的数据形成一个元素加入到列表中，而extend时将后段要加入的数据提取出其元素再加入到列表中去。举个栗子就是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:58:09.766719Z",
     "start_time": "2018-07-18T06:58:09.755186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kk: ['1', '2', '3', ['4', '5', '6']]\n",
      "aa: ['1', '2', '3', '4', '5', '6']\n"
     ]
    }
   ],
   "source": [
    "kk=['1','2','3']\n",
    "bb=['4','5','6'] \n",
    "kk.append(bb)\n",
    "print('kk:',kk)\n",
    "\n",
    "aa=['1','2','3']\n",
    "bb=['4','5','6'] \n",
    "aa.extend(bb) \n",
    "print('aa:',aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.选择最优特征分离："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "选取特征的方法是计算每个特征的信息增益值，然后找到具有信息增益值最大的特征作为划分的依据进行数据集划分，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般Python for语句前不加语句，但我在机器学习实战中看到了这两条语句：\n",
    "\n",
    "featList = [example[i] for example in dataSet]\n",
    "\n",
    "classList = [example[-1] for example in dataSet]\n",
    "\n",
    "多方研究和询问，得到如下解释：\n",
    "\n",
    "语句featList = [example[i] for example in dataSet]作用为： \n",
    "将dataSet中的数据按行依次放入example中，然后取得example中的example[i]元素，放入列表featList中\n",
    "\n",
    "语句classList = [example[-1] for example in dataSet]作用为： \n",
    "将dataSet中的数据按行依次放入example中，然后取得example中的example[-1]元素，放入列表classList中\n",
    "\n",
    "总而言之，类似上述两种for循环形式可以很方便地用来创建列表，如下例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T12:19:26.097207Z",
     "start_time": "2018-07-21T12:19:26.090771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    featList = [example[i] for example in myDat]\n",
    "    print(featList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T12:18:07.732413Z",
     "start_time": "2018-07-21T12:18:07.724864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 'yes']\n",
      "[1, 1, 'yes']\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    featList = [example for example in myDat[i]]\n",
    "    print(featList)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T02:31:20.637836Z",
     "start_time": "2018-07-24T02:31:20.618583Z"
    },
    "collapsed": true
   },
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob*calcShannonEnt(subDataSet)\n",
    "    infoGain = baseEntropy - newEntropy\n",
    "    if ( infoGain > bestInfoGain):\n",
    "        bestInfoGain = InfoGain\n",
    "        bestFeature = i\n",
    "    return bestFeature         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T02:33:27.640856Z",
     "start_time": "2018-07-24T02:33:27.606582Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选择最优特征进行分离\n",
    "def chooseBestFeatureToSplit(dataSet):#就算出信息增益之后选取信息增益值最高的特征作为下一次分类的标准\n",
    "    numFeatures = len(dataSet[0]) -1  # 计算特征数量，列表【0】表示列的数量，-1是减去最后的类别特征the last column is used for the labels，这是一个list，取行\n",
    "    baseEntropy = calcShannonEnt(dataSet) #计算数据集的信息熵\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "    #计算每一特征对应的熵，然后：iterate over all the features\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        #create a list of all the examples of this feature\n",
    "        #print('featList:', featList)\n",
    "        uniqueVals = set(featList)  # #确定某一特征下所有可能的取值 get a set of unique values\n",
    "        #print('uniqueVals:', uniqueVals)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value) #抽取在该特征的每个取值下其他特征的值组成新的子数据集\n",
    "            #print(' subDataSet:', subDataSet)\n",
    "            prob = len(subDataSet)/float(len(dataSet)) # 计算该特征下的每一个取值对应的概率（或者说所占的比重），子数据集在总的数据集中的比值\n",
    "            newEntropy += prob*calcShannonEnt(subDataSet)#计算该特征下每一个取值的子数据集的信息熵\n",
    "        infoGain = baseEntropy - newEntropy \n",
    "        #  print(\"第%d个特征是的取值是%s，对应的信息增益值是%f\"%((i+1),uniquevals,infogain))\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    # print(\"第%d个特征的信息增益最大，所以选择它作为划分的依据，其特征的取值为%s,对应的信息增益值是%f\"%((i+1),uniquevals,infogain)\n",
    "    return bestFeature\n",
    "    # 选出最优的特征，并返回特征角标 returns an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T12:11:49.521864Z",
     "start_time": "2018-07-21T12:11:49.515474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best feature is: 1\n"
     ]
    }
   ],
   "source": [
    "myDat, label = createDataSet()\n",
    "print ('the best feature is:', chooseBestFeatureToSplit(myDat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T02:45:51.853357Z",
     "start_time": "2018-07-18T02:45:51.829567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featList: [1, 1, 1, 0, 0]\n",
      "uniqueVals: {0, 1}\n",
      " subDataSet: [[1, 'no'], [1, 'no']]\n",
      "newEntropy: 0.0\n",
      " subDataSet: [[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "newEntropy: 0.5509775004326937\n",
      "infoGain: 0.4199730940219749\n",
      "featList: [1, 1, 0, 1, 1]\n",
      "uniqueVals: {0, 1}\n",
      " subDataSet: [[1, 'no']]\n",
      "newEntropy: 0.0\n",
      " subDataSet: [[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]\n",
      "newEntropy: 0.8\n",
      "infoGain: 0.17095059445466854\n",
      "the best feature is: 0\n"
     ]
    }
   ],
   "source": [
    "print ('the best feature is:', chooseBestFeatureToSplit(myDat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.统计出现次数最多的分类名称"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "决策树构建结束的标准是该分支下面所有的数据都具有相同的分类，如果所有数据都具有相同的分类，则得到的叶子结点或者终止块，任何到达这个叶子结点的必属于这个分类，上代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T02:31:38.531396Z",
     "start_time": "2018-07-24T02:31:38.520888Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#统计出现次数最多的分类名称\n",
    "def majorityCnt(classList):\n",
    "#针对所有特征都用完，但是最后一个特征中类别还是存在很大差异，比如西瓜颜色为青绿的情况下同时存在好瓜和坏瓜，无法进行划分，此时选取该类别中最多的类\n",
    "#作为划分的返回值，majoritycnt的作用就是找到类别最多的一个作为返回值\n",
    "    classCount={}#创建字典\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0 #如果现阶段的字典中缺少这一类的特征，创建到字典中并令其值为0\n",
    "        classCount[vote] += 1 #循环一次，在对应的字典索引vote的数量上加一\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #operator.itemgetter(1)是抓取其中第2个数据的值\n",
    "    #利用sorted方法对class count进行排序，并且以key=operator.itemgetter(1)作为排序依据降序排序因为用了（reverse=True）,3.0以上的版本不再有iteritems而是items\n",
    "    return sortedClassCount[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T01:28:12.648410Z",
     "start_time": "2018-07-23T01:28:12.639986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "myDat, label = createDataSet()\n",
    "classList2 = [example[-1] for example in myDat]# clasList 是所有类标签\n",
    "#majorityCnt(classList)\n",
    "print ( majorityCnt(classList2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "比如 \n",
    "1 yes\n",
    "1 yes\n",
    "1 yes\n",
    "1 no\n",
    "怎么添加标签呢\n",
    "classCount={'yes':3,'no':1}\n",
    "用频次来排序\n",
    "\n",
    "分类过程中不可能到最后分支之后所有的数据集都属于同一类，因为存在噪声数据，所以我们是找到分类结束时某个类别最多的类别作为该分支的叶节点的取值，上述代码就是找到数量最多的那一类作为叶节点的取值，其中用到了operator中的items函数，3.x以上的版本不再有iteritems而是items，而《机器学习实战》代码时基于2.x的版本的代码，所以经常会报错，建议大家写代码时边写边思考，从而找到一些不一样的东西，\n",
    "回到正题，items() 方法是把dict对象转换成了包含tuple的list，栗子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:16:41.359497Z",
     "start_time": "2018-07-18T07:16:41.349494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d: {'Adam': 95, 'Lisa': 85, 'Bart': 59} \n",
      " c: dict_items([('Adam', 95), ('Lisa', 85), ('Bart', 59)])\n"
     ]
    }
   ],
   "source": [
    "d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 }\n",
    "c = d.items()\n",
    "print('d:', d,'\\n',\n",
    "    'c:',c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T02:57:42.048050Z",
     "start_time": "2018-07-18T02:57:42.029081Z"
    }
   },
   "source": [
    "# 6.创建决策树"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "构建决策树用到的最基本的思想是递归，而递归结束的条件有两个：\n",
    "（1）在该分支下所有的类标签都相同，即在该支叶节点下所有的样本都属于同一类；\n",
    "（2）使用了所有的特征，但是样本数据还是存在一定的分歧，这个时候就要使用上诉的majoritycnt(classlist)函数了。\n",
    "\n",
    "在树的构建过程中，是每一次利用choosebestfeaturetosplit(dataset)函数找到在剩下的数据集中信息增益最大的特征作为分类的依据\n",
    "然后每次生成的tree是 mytree={bestfeatlabel:{}}这样的形式，保证了每次递归都在字典中存在子字典，从而最后完成决策树的构建。\n",
    "同时在构建过程中使用过的标签需要进行删除，从而不影响下一次特征的选取，同样也用到了set（）函数。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "决策树学习基本算法\n",
    "\n",
    "输入：训练集 D = {(x1,y1),(x2,y2)````(xm,ym)};\n",
    "     属性集 A = {a1, a2,`````,ad}.\n",
    "过程：函数TreeGenerate(D,A)\n",
    "1.生产节点node；\n",
    "2.if D中样本全属于同一类别C then\n",
    "3.   将node标记为C类叶节点；return\n",
    "4.end if\n",
    "5.if A=null OR D中样本在A上取值相同 then\n",
    "6.   将node标记为叶节点，其类别标记为D中样本数最多的类；then\n",
    "7.end if\n",
    "8.从A中选择最优划分属性a*；\n",
    "9.for a*的每一个值av* do\n",
    "10.   为node生成一个分之；令Dv表示D中在a*上取值为av*的样本子集\n",
    "11.   if Dv为空 then\n",
    "12.      将分支结点标记为叶结点，其类别标记为D中样本最多的类；return\n",
    "13.   else\n",
    "14.      以 TreeGenerate(Dv, A\\{a*})为分支结点\n",
    "15.   end if\n",
    "16.end if\n",
    "输出：以node为根结点的一棵决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T02:31:59.557110Z",
     "start_time": "2018-07-24T02:31:59.530816Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#创建决策树\n",
    "def createTree(dataSet, labels):\n",
    "    classList = [example[-1] for example in dataSet]#提取dataset中的最后一栏——种类标签 \n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        #计算classlist[0]出现的次数,如果等于classList，说明都是属于一类，不用继续往下划分\n",
    "        #按照classList[0]的类值，对classList进行统计，是否所有类标签的值完全相同，则直接返回该类标签\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:#看还剩下多少个属性，如果只有一个属性，但是类别标签又多个，\n",
    "        #就直接用majoritycnt方法进行整理  选取类别最多的作为返回值\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet) #选取信息增益最大的特征作为下一次分类的依据\n",
    "    bestFeatLabel = labels[bestFeat] #选取特征对应的标签 \n",
    "    myTree = {bestFeatLabel:{}} #创建tree字典，紧跟现阶段最优特征，下一个特征位于第二个大括号内，循环递归\n",
    "    del(labels[bestFeat]) #使用过的特征从中删除\n",
    "    featValues = [example[bestFeat] for example in dataSet]#特征值对应的该栏数据\n",
    "    # 抽取最优特征下的数值，重新组合成list\n",
    "    #print('featValues:',featValues)->featValues: [1, 1, 1, 0, 0]\n",
    "    uniqueVals = set(featValues)#找到featvalues所包含的所有元素，同名元素算一个\n",
    "    for value in uniqueVals:#遍历当前选择特征包含的所有属性值，每个数据集划分上递归调用函数createTree\n",
    "        subLabels = labels[:]#复制了类标签，并将其存储在新列表变量subLabels中\n",
    "        # 子标签的意思是循环一次之后会从中删除用过的标签 ，剩下的就是子标签了\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)#循环递归生成树\n",
    "        #print('myTree:',myTree)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T02:33:36.992453Z",
     "start_time": "2018-07-24T02:33:36.984828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mytree: {'no surfing ': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "mytree = createTree(myDat, labels)\n",
    "print('mytree:', mytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.使用matplotlib对生成的树进行注释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此过程中主要用到的是matplotlib中的annotate包，具体有很多方法和函数，我也只是过了一下书上的东西，有兴趣继续深入的可以参考：https://www.jianshu.com/p/1411c51194de\n",
    "http://blog.csdn.net/u013457382/article/details/50956459\n",
    "在此罗列一部分方法\n",
    "\n",
    "1.# 添加注释  \n",
    "2.# 第一个参数是注释的内容  \n",
    "3.# xy设置箭头尖的坐标  \n",
    "4.# xytext设置注释内容显示的起始位置  \n",
    "5.# arrowprops 用来设置箭头  \n",
    "6.# facecolor 设置箭头的颜色  \n",
    "7.# headlength 箭头的头的长度  \n",
    "8.# headwidth 箭头的宽度  \n",
    "9.# width 箭身的宽度  \n",
    "10.#plt.annotate(u\"This is a zhushi\", xy = (0, 1), xytext = (-4, 50),\\  \n",
    "11.# arrowprops = dict(facecolor = \"r\", headlength = 10, headwidth = 30, width = 20))  \n",
    "12.# 可以通过设置xy和xytext中坐标的值来设置箭身是否倾斜 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:47:38.020987Z",
     "start_time": "2018-07-18T07:47:37.978076Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import mpl\n",
    "\n",
    "mpl.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体\n",
    "mpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "#使用文本注解绘制树节点\n",
    "#包含来边框的类型，边框线的粗细等\n",
    "decisionNode = dict(boxstyle = \"sawtooth\", fc = '0.8', pad = 1)\n",
    "# boxstyle为文本框的类型，sawtooth是锯齿形，fc是边框线粗细  ,pad指的是外边框锯齿形（圆形等）的大小\n",
    "leafNode = dict(boxstyle = \"round4\", fc =\"0.8\", pad = 1)# 定义决策树的叶子结点的描述属性 round4表示圆形\n",
    "arrow_args = dict(arrowstyle='<-')#定义箭头属性\n",
    "\n",
    "def plotNode(nodeTxt, centerPt, parentPt, nodeType):\n",
    "    #annotate是关于一个数据点的文本 \n",
    "    #nodeTxt为要显示的文本，centerPt为文本的中心点，箭头所在的点，parentPt为指向文本的点  \n",
    "    #annotate的作用是添加注释，nodetxt是注释的内容，\n",
    "    #nodetype指的是输入的节点（边框）的形状\n",
    "    createPlot.ax1.annotate(nodeTxt,xy=parentPt,xycoords='axes fraction',\\\n",
    "                           xytext=centerPt, textcoords='axes fraction',\\\n",
    "                           va =\"center\", ha=\"center\", bbox=nodeType, arrowprops=arrow_args)\n",
    "    \n",
    "def createPlot():\n",
    "    fig = plt.figure(1, facecolor = 'white')\n",
    "    fig.clf()\n",
    "    createPlot.ax1 = plt.subplot(111, frameon = False)\n",
    "    plotNode(U'决策节点', (0.5, 0.1), (0.1, 0.5), decisionNode)\n",
    "    plotNode(U'叶节点', (0.8, 0.1), (0.3, 0.8), leafNode)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:47:39.251074Z",
     "start_time": "2018-07-18T07:47:38.963135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xlc1OW+B/DPyJIoF2EQjC0NOUoIiDmiCO4KYwm2GWa4\nJEungyeuZa/qWOeQa1KG1T3XE4ri2iklcSEWbzdywUREpTGXg4leFlEEFJSduX94BjWWGXBmfjM/\nPu/Xy9ernIfhw2Pz9en3+32fR6JUKpUgIiLR6iV0ACIi0i0WeiIikWOhJyISORZ6IiKRY6EnIhI5\nFnoiIpHTqNB/8803nb4eGxuLzz//HNu3b9dKKCIi0h61hX7//v1ISkrq8PW8vDxYWFggJiYGWVlZ\naGho0GY+IiJ6RGoLfXBwMAYMGNDh62lpafD39wcAuLm5IScnR3vpiIjokT3yNfqSkhLY2dkBAKRS\nKUpLS9sdl5CQAJlMBplMhoSEhEf9tkREpCFTbb6ZUqmERCJp97WoqChERUVp89sREZEGHnlF7+jo\niPLycgBARUUFHBwcHjkUERFpT5cKfXNzM65fv/7Q78nlcmRnZwMACgoK4Ovrq710RET0yNQW+r17\n9+LHH39EZmYmcnNzsWTJkodeHzlyJGpra7Fu3TpMnDgRZmZmOgtLRERdJ+E2xURE4sbOWCIikWOh\nJyISORZ6IiKRY6EnIhI5FnoiIpFjoSciEjkWeiIikWOhJyISORZ6IiKRY6EnIhI5FnoiIpFjoSci\nEjkWeiIikWOhJyISORZ6IiKRY6EnIhI5FnoiIpFjoSciEjkWeiIikWOhJyISORZ6IiKRY6EnIhI5\nFnoiIpFjoSciEjkWeiIikWOhJyISORZ6IiKRY6EnIhI5FnoiIpFjoSciEjkWeiIikWOhJyISORZ6\nIiKRY6EnIhI5FnoiIpEz1WRQbGwsbGxsYGtri7CwsDavX716FQcPHoRUKkVtbS3mzJmj9aBERNQ9\nalf0eXl5sLCwQExMDLKystDQ0NBmzLZt27Bw4UI8//zzKCsrw+3bt3USloiIuk5toU9LS4O/vz8A\nwM3NDTk5OW3GNDc349ixYwCAu3fvwtzcXMsxiYiou9QW+pKSEtjZ2QEApFIpSktL24xZsmQJ3n33\nXURFRWHEiBHo3bt3mzEJCQmQyWSQyWRISEjQQnTSphs3bqCsrEzoGESkA126GatUKiGRSNr8fnZ2\nNpYuXYrhw4d3WMSjoqKQm5uL3NxcREVFdS8t6czx48cxcuRI5OfnCx2FiLRMbaF3dHREeXk5AKCi\nogIODg5txmRkZEAulyM6OhqDBw+GQqHQflLSqRkzZmDt2rWYOnUqDh06JHQcItIitYVeLpcjOzsb\nAFBQUABvb29UVFQ8NMba2rr1n52dndu9dEOGLzQ0FDt37sRLL72ElJQUoeMQkZZIlEqlUt2gZcuW\nwcrKCra2tujduzfOnDmDFStWtL7+22+/4ejRo+jbty9u3ryJyMhInYYm3crNzUVwcDCWL1+OiIgI\noeMQ0SPSqNBTz3Px4kXI5XJERETg/fffb/feDBEZBxZ66lBJSQnkcjkmTpyIdevWoVcvNlITGSMW\neupUVVUVQkJC4OTkhC1btrBHgsgIcYlGnbK2tkZGRgbq6uowY8YMVFdXCx2JiLqIhZ7UsrCwwK5d\nuzBw4EBMnjwZN27cEDoSEXUBCz1pxNTUFAkJCZDL5fD390dhYaHQkYhIQxrtXkkEABKJBMuXL4e9\nvT0CAgLw/fffw9vbW+hYRKQGCz112Z///GfY2dlh2rRp2L17N8aNGyd0JCLqBJ+6oW47ePAg5syZ\ng40bN2LmzJlCxyGiDnBFT902bdo0pKWlITg4GDdu3GAXLZGBYqGnRyKTyfDTTz8hKCgI169fZxct\nkQHipRvSClUX7aRJkxAfH88uWiIDwkJPWsMuWiLDxGUXaY2qi7a2tpZdtEQGhIWetMrCwgK7d+9m\nFy2RAWGhJ61TddEGBQUhICCAXbREAuNTN6QTEokEK1aswIABA9hFSyQwFnrSKVUX7dSpU5GcnMwu\nWiIB8NIN6dzs2bOxY8cOvPjii9i7d6/QcYh6HK7oSS+mTZuG77//HsHBwSgvL0d4eLjQkYh6DBZ6\n0pvfd9G+99577KIl0gM2TJHesYuWSL9Y6EkQqi5aZ2dnJCUlsYuWSIe4lCJBqLpo7969i+DgYNTU\n1AgdiUi0WOhJMKouWhcXF3bREukQCz0JytTUFBs2bEBgYCC7aIl0hE/dkOAe7KIdN24cvv/+e3h5\neQkdi0g0WOjJYDzYRcuzaIm0h0/dkMFRnUWbmJiIkJAQoeMQGT2u6MngqLpoQ0JCcOPGDXbREj0i\nFnoySKNGjWIXLZGW8NINGTRVF+3kyZPx2WefsYuWqBtY6MngVVVVITg4GC4uLuyiJeoGLo/I4Flb\nWyMzMxN37txhFy1RN7DQk1GwsLBAcnIyu2iJukGjSzexsbGwsbGBra0twsLC2h2TmJgIS0tLnDx5\nEnFxcVoPSgQASqUSH3zwAXbv3o3MzEwMHDhQ6EhEBk/tij4vLw8WFhaIiYlBVlYWGhoa2ozJzs6G\ng4MDQkND4eHhoZOgRMC9LtqVK1ciOjoaAQEB+OWXX4SORGTw1Bb6tLQ0+Pv7AwDc3NyQk5PTZkxy\ncjJGjRoFAFiwYIF2ExK1480330RcXBymTp2KI0eOCB2HyKCpLfQlJSWws7MDAEilUpSWlrYZU1hY\niAMHDmDt2rX48MMP232fhIQEyGQyyGQyJCQkPGJsIuCVV17Btm3b8MILL2Dfvn1CxyEyWF1qmFIq\nle02rVRXV8PX1xfDhg3DX//6V1y9ehVPPPHEQ2OioqIQFRX1aGmJficwMBCpqakICQlBeXk5Fi5c\nKHQkIoOjdkXv6OiI8vJyAEBFRQUcHBzajOnfvz9cXFwAAC4uLu2u+ol0ZdSoUcjKysLy5cuxevVq\nsDWE6GFqC71cLkd2djYAoKCgAN7e3qioqHhozPjx45GbmwsAKC8vh6urqw6iEnVs6NChOHr0KHbu\n3InFixejpaVF6EhEBkOjxyuXLVsGKysr2Nraonfv3jhz5gxWrFjR+nptbS1WrVqFESNGoLGxEaGh\noToNTdSRyspKhISE4IknnsDmzZvZRUsEboFAIlRbW4vZs2ejrq4OycnJsLS0FDoSkaDYGUuio+qi\ndXZ2ZhctEVjoSaRMTU2xceNGTJs2DQEBAbhy5YrQkYgEw/3oSbRUXbQDBgxAQEAA0tLS4OnpKXQs\nIr1joSfRe/PNN2FnZ4cpU6YgOTkZAQEBQkci0ivejKUeIzMzE6+++irPoqUehyt66jFUXbQzZ85k\nFy31KCz01KP4+voiKysLcrkc169fx7vvvsuzaEn0eOmGeqTi4mLI5XJMnToVa9eu5Vm0JGos9NRj\nsYuWegouY6jHsrGxQWZmJmpqahASEsKzaEm0WOipR1N10To5OWHKlCmtO7USiQkLPfV4qi7aKVOm\nsIuWRIlP3RDhXhftqlWr2EVLosRCT/SAmJgYdtGS6PCpG6J2ZGZmIiwsDImJiQgODhY6DtEj4TV6\nonYEBgbiwIEDiIyMxObNm4WOQ/RIenShr6+vx5kzZ4SOQQbK19cXP/30Ez766CN8/PHHPIuWjFaP\nLvTl5eUIDg5GZGQkqqqqhI5DBkh1Fu2OHTvw1ltv8SxaMko9utA7OTlBoVDAzMwMnp6e2Ldvn9CR\nyAA5OTnh0KFDOHHiBObOnYuGhgahIxF1CW/G/ttPP/2EiIgIjBw5El988QXs7e2FjkQGpra2FqGh\noWhoaMDu3bt5Fi0ZjR69on/QhAkTkJ+fj4EDB8LLywvbt2/nNVl6iIWFBb777jt20ZLR4Yq+Hbm5\nuVi4cCFcXFzwj3/8Ay4uLkJHIgOiVCqxdOlSfPfdd8jIyMDAgQOFjkTUKa7o2yGTyZCbmws/Pz88\n/fTTWL9+PW/CUStVF+0bb7yBgIAAKBQKoSMRdYorejV+/fVXhIeHw9zcHBs3bsQf/vAHoSORAdm5\ncycWL17MLloyaFzRq+Hh4YEjR47ghRdegJ+fH+Li4tDU1CR0LDIQc+bMwdatW/H8889j//79Qsch\nahdX9F1w+fJlREVFobKyEomJiRg+fLjQkchA5OTkYObMmVi1ahVee+01oeMQPcQkNjY2VugQxsLG\nxgZz586FmZkZ5s+fj9u3b8Pf3x+mptwbrqdzcnJCcHAwIiIiUF9fD39/f55FSwaDl266SCKRYOHC\nhTh9+jQUCgVGjBiBY8eOCR2LDICqi3b79u14++23eQOfDAYv3TwCpVKJ5ORkvPnmm3j55ZexYsUK\nNtEQKisrERwcjEGDBmHTpk08i5YExxX9I5BIJHjppZfwyy+/oLKyEl5eXjh48KDQsUhgqrNob9++\nzbNoySBwRa9F6enpeP311zF16lR8+umnsLGxEToSCaipqQmvv/46FAoFUlNT0b9/f6EjUQ/FFb0W\nyeVyKBQKWFhYwNPTE3v27BE6EglIdRbt5MmTeRYtCYoreh05fPgwIiIi4O3tjS+//BKPP/640JFI\nQOvWrcPatWuRnp6OYcOGCR2Hehiu6HVk3LhxOHPmDNzc3DB8+HBs3bqVm6T1YP/5n/+JNWvWYPLk\nyTh69KjQcaiH4YpeD/Ly8hAeHo4BAwbgq6++4iZYPVhGRgbCwsKwadMmnkVLeqPRij42Nhaff/45\ntm/f3um49PR0JCUlaSOXqDz99NPIycnBhAkTIJPJ8Pe//53PWPdQQUFBSE1N5Vm0pFdqC31eXh4s\nLCwQExODrKysDk/XUSqVSElJ0XpAsTAzM8P777+Pw4cPY+fOnZgwYQIuXLggdCwSgK+vL7KysvDR\nRx9hzZo1vKRHOqe20KelpcHf3x8A4ObmhpycnHbHZWZmIjAwULvpRMjd3R2HDx9GaGgo/P39sXr1\najQ2Ngodi/TM3d0dR48exbZt29hFSzqnttCXlJTAzs4OACCVSlFaWtpmTHNzM2pqaiCVSjt8n4SE\nBMhkMshkMiQkJDxCZOPXq1cvLFq0CLm5ucjKysLo0aNx6tQpoWORnjk5OeHw4cPIycnBvHnzeBYt\n6UyXnrpRKpXtbtSUlpYGuVze6ddGRUUhNzcXubm5iIqK6lpKkRo0aBDS09MRExODoKAg/OUvf0Fd\nXZ3QsUiPft9Fe+fOHaEjkQipLfSOjo6tZ2NWVFTAwcGhzZiamhqcOHECp0+fxvnz51FUVKT9pCIl\nkUgwf/585Ofn41//+hd8fHz4+F0P06dPH3z33XdwdHTE5MmTeRYtaZ3aQi+Xy5GdnQ0AKCgogLe3\nNyoqKh4aM3v2bEycOBE+Pj5wd3eHs7OzbtKK2OOPP45du3Zh1apVmDVrFv785z+jurpa6FikJ6am\npkhMTMTkyZMxbtw4XL16VehIJCJqC/3IkSNRW1uLdevWYeLEiUhPT8dnn33WZlxFRQXS09Px448/\n4saNGzoJ2xO88MILOHv2LO7cuQMvLy9kZGQIHYn0RCKRYPXq1Xj99dcREBCAs2fPCh2JRIINUwYs\nMzMTUVFRmDBhAuLj4zu92U3ismPHDrz11lvYs2cPxo4dK3QcMnLcAsGABQYGQqFQwNraGp6enti9\ne7fQkUhPXn31VWzZsgUzZ87EgQMHhI5DRo4reiNx9OhRREREwMPDA//1X//V7k1xEp/jx49j5syZ\n+Pjjj7FgwQKh45CR4oreSPj7++PUqVN46qmnMHz4cGzevJkdlT3A6NGjkZWVhdjYWMTFxfHPnLqF\nK3ojdPr0aYSHh8PW1hZfffUVnnzySaEjkY4VFxcjKCgIQUFB+OSTT9CrF9dopDn+12KEfHx8cPz4\ncUyZMgWjRo3CF198gebmZqFjkQ6pumiPHz+O+fPnc9sM6hKu6I3cxYsXERERgaamJiQmJuKpp54S\nOhLp0N27dxEaGoqmpibs3r0bffv2FToSGQGu6I3ckCFDkJWVhbCwMIwbNw4rV67kak/E+vTpgz17\n9sDBwQFTpkzBzZs3hY5ERoCFXgR69eqFP/3pT8jLy8ORI0cgk8lw8uRJoWORjqi6aCdOnIiAgAB2\n0ZJaJrGxsbFChyDt6NevH1599VVYWlpi/vz5KC8vR0BAAMzMzISORlomkUgwdepUNDY2IioqCoGB\ngbC3txc6FhkoruhFRiKRYO7cucjPz0dhYSGGDx+OQ4cOCR2LdGTx4sVYvXo1Jk+e3LonFdHv8Was\nyKWkpGDRokUICQnBxx9/DCsrK6EjkQ6kp6dj7ty5SEpKwrPPPit0HDIwXNGL3HPPPQeFQoGGhgZ4\nenri+++/FzoS6YBcLseBAwcQERGBLVu2CB2HDAxX9D3IDz/8gMjISPj7+yM+Ph79+/cXOhJp2fnz\n5yGXyxEdHY133nlH6DhkILii70GmTJmCX375Bf3794eXlxe+/fZbttSLjLu7O44cOYItW7ZgyZIl\nPIuWAHBF32P9/PPPCA8Pxx/+8Af893//NxwdHYWORFpUUVGB4OBguLq6YtOmTXzyqofjir6HGjNm\nDPLy8uDt7Y3hw4dj48aNXN2LiFQqxcGDB1FVVcWzaIkregLy8/MRHh4OKysrbNiwAa6urkJHIi1p\nampCZGQkzp07h9TUVNja2godiQTAFT3B29sbx44dw/Tp0+Hr64v4+HhukiYSpqam2LRpE7toeziu\n6OkhBQUFiIiIQF1dHRITEzFs2DChI5GWxMfHIz4+Hmlpafxz7WG4BQI9RCqVYt68eWhpacG8efNQ\nV1cHPz8/mJiYCB2NHpGfnx/s7Ozw6quvwt/fHy4uLkJHIj3hip46VFRUhD/+8Y+4cuUKNm3ahFGj\nRgkdibQgPT0d8+bNw+bNm9lF20NwRU8dsrKywiuvvAJra2vMnz8fZWVl3CRNBNzc3DB+/Hi88sor\nsLOzg4+Pj9CRSMd4M5Y6JZFIMGfOHCgUChQXF8Pb2xtZWVlCx6JHpDqL9m9/+xs++eQToeOQjvHS\nDXXJvn37EB0djWeeeQZxcXHo16+f0JHoERQVFUEul0MulyMuLo5n0YoU/1SpS0JCQqBQKAAAnp6e\nOHDggMCJ6FE4Ozvj0KFDOHbsGBYsWMDTyUSKK3rqth9//BGRkZHw9fXF559/Djs7O6EjUTepzqJt\nbm7Grl27eBatyHBFT902adIk5Ofnw9HREV5eXvj666+5jYKR6tOnD7777jsMGDCAZ9GKEFf0pBU5\nOTkIDw/HoEGDsH79ejg7OwsdibpBqVTivffew759+5CRkYEnnnhC6EikBVzRk1b4+vri5MmTkMlk\nGDFiBL766itukWuEJBIJ1qxZg8jISAQEBODXX38VOhJpAVf0pHUKhQLh4eHo06cPNmzYADc3N6Ej\nUTds374dS5YswZ49e+Dn5yd0HHoEXNGT1nl6eiI7OxvBwcEYM2YMPv30UzQ1NQkdi7ooLCwMSUlJ\nCAkJQWpqqtBx6BFwRU86denSJURGRqKmpgaJiYnw8vISOhJ10fHjxzFz5kzExcVh3rx5QsehbuAW\nCKRTqk3SevXqhXnz5uHOnTsYO3YsTE1NhY5GGnJ2dsaMGTOwcOFCNDU1wd/fX+hI1EVc0ZPeFBcX\n44033sClS5eQmJiIMWPGCB2JuqCoqAhBQUGYPn06u2iNjEaFPjY2FjY2NrC1tUVYWFib12tqavDN\nN9/AysoKJSUliImJ0UlYMn5KpRLffvstYmJiMGfOHCxfvpzNOUZEdRbt4MGDkZiYyA3ujITav5Lz\n8vJgYWGBmJgYZGVloaGhoc2Ybdu2YcSIEZg1axYKCwtx+/ZtnYQl4yeRSBAaGgqFQoHr16/Dy8sL\nP/zwg9CxSEOqs2grKirw3HPP8SxaI6G20KelpbVek3Nzc0NOTk6bMe7u7qivrwdw74Nsbm6u5Zgk\nNv3798f27dvx5Zdf4rXXXkNkZCSqqqqEjkUa6NOnD/bs2QN7e3tMnTqVXbRGQG2hLykpad3DRCqV\norS0tM2YSZMmwc/Pr7XY9+7du82YhIQEyGQyyGQyJCQkPGpuEolnn30WCoUCpqam8PT0xN69e4WO\nRBowMzPDpk2bMH78eIwbNw7/93//J3Qk6kSXHn1QKpWQSCQdvp6UlIQPPvig3deioqIQFRXVtXTU\nI1hZWWH9+vWYPXs2IiIi8PXXX+OLL76Avb290NGoE6ou2gEDBiAgIABpaWnw8PAQOha1Q+2K3tHR\nEeXl5QDu3YhxcHBod1x6ejomTJgAqVSq3YTUY0yYMAH5+fkYOHAgvLy8sH37dm6SZgTeeustrFy5\nEpMmTcKxY8cA3Ltvd+XKFYGTkYraQi+Xy5GdnQ0AKCgogLe3NyoqKh4aU1RUhJaWFri7u+Py5cso\nKCjQTVoSPQsLC6xZswapqamIi4vDs88+i6tXr7a+3tzczD10DJCqi3bmzJlITU3F+fPn8fnnnwsd\ni/5NbaEfOXIkamtrsW7dOkycOBHp6en47LPPHhqzfv16bN26FbNnz0ZwcDAcHR11Fph6BplMhtzc\nXIwdOxYjR47E+vXr0dLSgo0bN+KNN94QOh61Y/r06di/fz/Cw8NhbW2N7du3t/uUHukfG6bI4P36\n668IDw+HmZkZ4uPjMWPGDOzbtw+jRo0SOho94OTJk9i8eTPc3d2xZs0aPPbYY/j444/x0ksvCR2t\nx2NrGxk8Dw8PZGVlwcPDA4GBgQgICMCiRYvavYTT1NSEjIwMtZd3DH2cMRo8eDCefPJJ7N27F5WV\nlSgsLMT7778vdCwCACWRgWtsbFSOHDlSaWFhoXzqqaeUbm5uShMTE+Xy5cvbjHvxxReVffv2Vc6f\nP1/Z3Nzc4fsZ8jgxqK6uVu7cuVO5aNEijb+mublZWV5errx48aLy3Llz7f66dOmSsrKyUtnS0qLD\n9OLDSzdk0JqamjB79mxcu3YNy5Ytw1tvvYXm5maYmprC2dkZ+/fvf2hcWVkZPvroI7z77rsYNmwY\nNm3a9NCeLIY+Tszu3r2Lc+fO4ZdffkF+fj4uXLiA8vJy3Lx5ExUVFbh9+zYsLS1hbW0NExOTdt+j\noaEBt27dQm1tLaytrSGVSmFrawt7e3sMGzYMXl5e8PLywpAhQ7g9wwNY6MlgPVgcVdd8a2trsXjx\n4oeKpFjGiU1LSwt++uknbNu2DYcOHUJRUREGDRrUeoln0KBBsLGxgbW1Nfr164f/+I//0HhX08bG\nRty6dav1V3l5OS5fvtz61N+1a9fg6uqKwMBAzJs3Dz4+Pp32AIkdCz0ZpPaKo8qDRTIhIQFz5swx\n+nFiKvZXr17FF198ga+//hr9+vVDYGAg/Pz8MGjQIL1tT11XV4dLly7h0KFDyMjIgKWlJcLCwhAd\nHQ1ra2u9ZDAkLPRkkMLCwnDlypU2xVFFVSTLysowcOBAox8nk8mwfv16TafHYGVlZeHll1+GXC7H\ns88+axDHSCqVSpw5cwZ79uzB+fPnkZqaiqFDhwodS69Y6MkgyeVymJub44MPPujwem1tbS0yMjIw\nffr0douoMYxramrCX//6V/Tr1w/ffvtth+9lDHJycjB9+nSsXLnSYB993bNnD5KSknD8+HE4OTkJ\nHUdvWOjJIN25cwfTp0+HVCrF0qVLRXNZ40GqIi+RSJCSktLuZoDGoqGhAV5eXnjttdcwbdo0oeN0\n6quvvsK1a9ewb98+oaPojfg+PSQKffv2RVpaGioqKrBy5UrRPXcupiIPAJ988gkcHBwwdepUoaOo\n9dprr0GhUPSoQs8VPRk0Ma7sxVbk79y5AycnJ2zdutVoLoccPXoUCQkJUCgUQkfRC+P/1JCoPbiy\n//TTT4WOoxUrVqwQTZEHgJSUFHh7extNkQcAPz8/VFZW4syZM0JH0QsWejJ4jz32GOzt7bt0ROW1\na9c6fO3By0B1dXUavZ+m4zRx69Yt2Nvbi6ahZ+vWrQgKCury17W0tKCpqUntOG3OvUqvXr0QFBSE\nrVu3av29DRELPRm0B5+n//DDDzX+ugMHDrT7++Xl5Th48CAAoLS0FEeOHMHdu3dRU1PTZmxmZmbr\n7ovJycmdfr8ff/xR450aV61ahXPnziE8PNzo7z0olUr8/PPPGDNmTJe/ViKRdPikka7m/kGjR49u\n3YJd7FjoyWB11jT1excvXsRvv/3W+u82NjYA0Hpojkp6ejpu3LiB1NRUHD9+HAqFArm5uaisrARw\nr3Ddvn0bxcXFKCkpwf/+7//iwIEDuHbtGtLT05GVldXu96+trYW5uTnq6upw+fLlTn8uCwsLxMfH\n4+zZs1i4cKFRF/vi4mKYm5tr1ISk+stUtUKXSCQPfZ0+5v5BgwcPxrlz53rE4Tb6aVMj6qKuFHkA\nGDJkCI4ePYrevXsjLy8P58+fR1paGi5fvow//elPAIALFy4gICAAJSUlMDc3h5WVFdzd3WFpaYn+\n/fsDuFd8zp07hz59+sDa2hoymQxlZWWYOnVqp9fTlUolMjIyYGZmBmtrazg6OnaaWVXsFy9ejIUL\nFxptZ+z58+fh6uqq0djk5GQMGDAAFy5cQExMzEOvKf99TKk+5l7FxsYGJiYmKCsrw+OPP67Rz2Cs\nWOjJIC1YsEDjIq/i4uICU1NTzJgxA8C9gzBSUlJaXzczM8O5c+dgbm6Oy5cvo7GxsfUDPnz48NZj\nMocNG4YbN26gf//+OH78OJqbm3H58mWcP38eb7/99kN7ply9ehUNDQ24ceMGhg4diuLiYgwZMkSj\nzA8W++joaKPsjK2rq4OFhYVGY+3t7SGXy1FfX499+/bBxMQE+fn5aGlpwd27d/HMM8/obe5VLCws\ndHIPwNCw0JNBKi8vh42NTZf2Rvn111/h4+ODc+fO4cKFCzA1NUVhYSH27NmDoKAguLq6ora2Fpcu\nXUJdXR3Mzc0BAFeuXIFcLm99n5aWFlRWVsLNzQ0nTpxASEgIgHv/l/H7jbEee+wxHD58GOPGjYOt\nrS1u3rzZpadPzMzMIJVKcfPmTY2/xljdvn0bmZmZaGxsxAsvvIBevXpBIpHgmWeeeWiMvua+J2Gh\nJ4OUnJzrxXwrAAAJ+UlEQVSM6dOnY9WqVWqfn6+qqsLFixfRr18/FBUVoaSkBKNHj4a1tfVDBRy4\ntwIdPXo0rly50vqezc3ND42xsrLC008/DeDe0xk1NTXo27dvu0/J9OrVCy0tLSguLkZBQQEuXbrU\nehlCnQefpzfWpz/MzMxQX1+v0VgXFxf4+fl1Ojf6mnuV+vp60Tz91BnjuyhIPUJXOmOtra2Rk5OD\nMWPGQCaToampCQEBASgoKGjz+J6joyNKS0tx8uTJ1lW0j49Ph++tVCphYmKCL7/8EoMHD27zupmZ\nGYYOHQpfX1/4+vpi0aJFDx1m3hGxNE0NGTIEV65c0Wjs2LFju1SEdTX3KtXV1aitrW29ZCdmLPRk\nsLpS7BctWgSJRIKcnBz4+voCAMaPH4+1a9eiqqqqdVxJSQlMTU0xduxYeHh4wNzcHDdu3Og0h4WF\nBf74xz+22fGwrq4OZWVlqKiogImJCf7nf/4H9fX1OHPmDE6fPt3h+4mlyAPAwIEDcevWrXYfT9VE\nY2Njp69re+4fdOnSJbi7uxvlTfCuEv9PSEatK52xZ8+ehVQqhbOzMwBAKpXC2toa77zzDk6dOoWz\nZ8/Cw8MDnp6eMDExgZmZGby9vXHr1i1kZWW1e1NOdY/A3Ny8zWr0n//8JwYNGoQnn3wS1dXV8PX1\nRX19PYKDg1FdXd1hTjF1xvbq1QsjR45Ebm5ul79WqVR2+limLub+QSdPnsTo0aO7nNsYca8bMniq\nRy3v3LmDFStWdDimrq4OlpaWesvV0tLSrdXg4sWLMWjQIGzevLnDLZiNyYYNG7Br1y6sXr1ab9+z\nu3OvolQq8fLLL2PHjh3w8/PTYjLDxBU9GTRNO2NNTU31WuQBdLvQiKkzFgBmzZqFn3/+Wa9PDj3q\n5RbVHjfd6eg1Riz0ZLC62jRlLMTUGQvcuxkeERGBL7/8UugoGmlubkZ8fHzrfZKegIWeDJJYi7yK\n2Ir9smXLcOrUKZw4cULoKGrt2rULUqkU8+fPFzqK3rDQk0HSpDO2qakJx44dU1skDXXcg8U+Ojq6\n0/cydJaWlti0aRM+/PBD/Otf/xI6TocOHz6MpKQkbNiwoces5gHAJDY2NlboEES/l5CQAEtLS0yc\nOLHd67GqRxS3bNmCoqIijBs3rt0PrqGPk0gk+Pnnn9HS0oJZs2ZpOj0GafDgwRg4cCCio6NhYmIC\nZ2dnjbdH0LXi4mJs3boVmzdvxr59+zrtnRAjrujJICUnJ6OqqgqrVq1qsyJ+8Dn0wsLCDp+zN6Zx\nxtoZ+3uhoaH44YcfUFxcjBdffBFvv/02MjIyNH7kUZvKy8uxe/duvP7661i4cCEee+wx5Obm9pgb\nsA/i45VksNo7RrC9ZiOxjBOb6upqpKSkYMuWLTh27Bj69esHNzc3uLq6wtXVFYMGDYJUKkW/fv1g\nYWHR5UspSqUSNTU1uHXrFm7evInffvut9VdBQQGam5sxZcoUzJ8/H0FBQa17G/VELPRk0B4sku+9\n9x7+9re/tVscxTJOrFpaWlBYWAiFQoH8/Hzk5+fjwoULuHnzJm7evImWlhZYW1vD2toaVlZWHW5m\n19jYiFu3bqGqqgpVVVXo3bs3pFIp7OzsMGzYMHh7e8PLywuenp5wcHDoUdfhO8NCTwZPVSQLCgrg\n7e3dYXEUy7ieqLa2trXoV1RUtNloTsXMzAy2tratv3ryKr0rWOjJKNy5cwdff/01wsLCOi2OYhlH\npE0s9EREIsenboiIRI6FnohI5DQ6YSo2NhY2NjawtbVFWFhYm9ebm5vx3nvvwd7eHt7e3ggKCtJ6\nUCIi6h61K/q8vDxYWFggJiYGWVlZaGhoaDNm7969kMlkeOedd7Bjxw6dBCUiou5RW+jT0tLg7+8P\nAHBzc0NOTk6nY/r06YOioiItxyQiou5SW+hLSkpgZ2cH4N6JPaWlpd0ak5CQAJlMBplM1u7ln54q\nISFB6AgGg3NxH+fiPs7Ffd2diy7djNXkhPWOxkRFRSE3Nxe5ubk4f/5811KKGP8jvo9zcR/n4j7O\nxX06K/SOjo4oLy8HAFRUVLR7YromY4iISBhqC71cLkd2djYAtLZuV1RUdDimtrYWTk5OOohKRETd\noXY/ekdHR/zwww84deoUPDw8UFhYiJSUFEyePLl1zNChQ7Ft2zbk5eUhMDAQbm5uar/xyJEjHzm8\nWHAu7uNc3Me5uI9zcV935oJbIBARiRw7Y4mIRI6FnohI5DTaAqG7uHXCfermoqamBt988w2srKxQ\nUlKCmJgYAVLqh7q5UElPT8e1a9ewYMEC/YXTM03mIjExEZaWljh58iTi4uL0nFB/1M3F1atXcfDg\nQUilUtTW1mLOnDkCpNSPb775BqGhoR2+rulnSEVnK3punXCfJnOxbds2jBgxArNmzUJhYSFu374t\nQFLd02QugHv9GCkpKXpOp1+azEV2djYcHBwQGhoKDw8PAVLqh6afkYULF+L5559HWVmZaD8j+/fv\nR1JSUoeva/oZepDOCj23TrhPk7lwd3dHfX09AEAikYj25BxN5gIAMjMzERgYqM9oeqfJXCQnJ2PU\nqFEAIOr/s9FkLpqbm3Hs2DEAwN27d0X7GQkODsaAAQM6fF3Tz9CDdHbpprtbJzg7O+sqkmA0mYtJ\nkyYBQGuxF+vpQ5rMRXNzM2pqamBrayvaVRug2VwUFhbiwIEDqKioQFVVFZYvX67vmHqhyVwsWbIE\nQUFBeOqpp/Dcc8+J9jOijiZz9Xt6uRn7KFsniI26nzMpKQkffPCBHhMJp6O5SEtLg1wuFyCRcDqa\ni+rqavj6+uLtt9+GRCLB1atXBUinXx3NRXZ2NpYuXYrhw4dzW4R/07Ru6qzQc+uE+zT9OdPT0zFh\nwgRIpVJ9xtMrTeaipqYGJ06cwOnTp3H+/HnRXtLTZC769+8PFxcXAICLi4tGqzdjpMlcZGRkQC6X\nIzo6GoMHD4ZCodB3TIPQnbqps0LPrRPu02QuioqK0NLSAnd3d1y+fBkFBQVCRNU5TeZi9uzZmDhx\nInx8fODu7i7Ky3mAZnMxfvx45ObmAgDKy8vh6uqq95z6oMlcWFtbt/6zs7Nzj7h009zcjOvXrz/0\ne7+fK19fX7Xvo9PO2GXLlsHKygq2trbo3bs3zpw5gxUrVrS+3tzcjL/85S+QSqXw8fER9eOV6uZi\n6dKluHTpEgBAoVAgJycHffr0ESquTqmbC+DeSiUuLg6lpaX49NNPW69Jio26uaitrcWqVaswYsQI\nNDY2dvrInbFTNxe//fYbjh49ir59++LmzZuIjIwUMK3u7N27F2+++SY2bNiAfv364e9//zu2bt36\n0JgH52ru3Llq35NbIBARiRw7Y4mIRI6FnohI5FjoiYhEjoWeiEjkWOiJiESOhZ6ISORY6ImIRO7/\nAbEGRS9ys1jgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cbf7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "createPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.计算树的叶节点数目和树的层数"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "getnumleafs（）函数和gettreedepth（）函数在结构和方法上都比较类似，\n",
    "因为tree字典中的每一个大括号的第一个字符都是它对应的键值，所以我们只需要判断第二个还是不是键值，如果是的话说明还有树或者深度，都是用了递归的思想，在每次循环中都先找到该字典中的第一个字符，然后判断在该键值下的第二个字符是不是还是键，是的话说明还有深度或者层数，不是的话说明已经找完了。其中遇到了这样的问题：\n",
    "（1）一开始写这句的时候if type(seconddict[key]).__name__=='dict':书上的是.-name-（单个下划线），但是实际上是双下划线，再者当不加.__name__得时候type函数获得的是字典得类型，而不是本身就是字典，所以要加上name表示这个名字叫做“dict”。\n",
    "（2）2.x的版本中是firststr=mytree.keys()[],但是dict_keys型的数据不支持索引，所以强制转换成list即可，即 firststr=list(mytree.keys())[0]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T09:01:15.460700Z",
     "start_time": "2018-07-18T09:01:15.429030Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#获取叶节点的数目和树的层数\n",
    "def getNumLeafs(myTree):#计算叶子节点的个数（不包括中间的分支节点）  \n",
    "    numLeafs = 0\n",
    "    firstStr = list(myTree.keys())[0]# 获得myTree的第一个键值，即第一个特征，分割的标签   \n",
    "    #遇到的问题是mytree.keys()获得的类型是dict_keys，而dict_keys不支持索引，我的解决办法是把获得的dict_keys强制转化为list即可  \n",
    "    secondDict = myTree[firstStr]# 根据键值得到对应的值，即根据第一个特征分类的结果   \n",
    "    for key in secondDict.keys(): #获取第二个小字典中的key  \n",
    "        if type(secondDict[key]).__name__=='dict':\n",
    "            #判断是否小字典中是否还包含新的字典（即新的分支）   \n",
    "            #书上写的是.-name-但是3.0以后得版本都应该写成.__name__(两个下划线) 重点！！！ \n",
    "            numLeafs += getNumLeafs(secondDict[key])\n",
    "            #包含的话进行递归从而继续循环获得新的分支所包含的叶节点的数量  \n",
    "        else:  numLeafs += 1#不包含的话就停止迭代并把现在的小字典加一表示这边有一个分支  \n",
    "    return numLeafs\n",
    "\n",
    "def getTreeDepth(myTree):##计算判断节点的个数  \n",
    "    maxDepth = 0\n",
    "    firstStr = list(myTree.keys())[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__=='dict':\n",
    "            thisDepth = 1+ getTreeDepth(secondDict[key])\n",
    "        else: thisDepth = 1\n",
    "        if thisDepth > maxDepth:\n",
    "            maxDepth = thisDepth #间隔 间隔间隔得问题一定要多考虑啊啊啊啊啊啊  \n",
    "    return maxDepth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.成决策树图形"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xOff\n",
    "\n",
    "xOff和yOff用来记录当前要画的叶子结点的位置。\n",
    "画布的范围x轴和y轴都是0到1，我们希望所有的叶子结点平均分布在x轴上。totalW记录叶子结点的个数，那么 1/totalW 正好是每个叶子结点的宽度\n",
    "如果叶子结点的坐标是 1/totalW , 2/totalW, 3/totalW, …, 1 的话，就正好在宽度的最右边，为了让坐标在宽度的中间，需要减去0.5 / totalW 。所以createPlot函数中，初始化 plotTree.xOff 的值为-0.5/plotTree.totalW。这样每次 xOff + 1/totalW ，正好是下1个结点的准确位置\n",
    "yOff\n",
    "yOff的初始值为1，每向下递归一次，这个值减去 1 / totalD\n",
    "cntrPt\n",
    "cntrPt用来记录当前要画的树的树根的结点位置\n",
    "在plotTree函数中，它是这样计算的\n",
    "cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)\n",
    "numLeafs记录当前的树中叶子结点个数。我们希望树根在这些所有叶子节点的中间。\n",
    "plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW\n",
    "这里的 1.0 + numLeafs 需要拆开来理解，也就是\n",
    "plotTree.xOff +  float(numLeafs)/2.0/plotTree.totalW +1.0/2.0/plotTree.totalW\n",
    "plotTree.xOff +  1/2 * float(numLeafs)/plotTree.totalW + 0.5/plotTree.totalW\n",
    "因为xOff的初始值是-0.5/plotTree.totalW ，是往左偏了0.5/plotTree.tatalW 的，这里正好加回去。这样cntrPt记录的x坐标正好是所有叶子结点的中心点\n",
    "#plottree.totalw和plottree.totald是全局变量  \n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T09:01:17.938394Z",
     "start_time": "2018-07-18T09:01:17.564579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muytree: {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADxCAYAAAD8x81kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xk8len/P/CXXagRCllCRNREaZlGoYWoadU2bTNt2hcz\nTVMTKU3LtKlp9W1SVNpHUSSSNmRpo+zSKEuK7OSc6/dHn/zGpFIc93HO+/l49Mdwua+XZV69O+5F\ngjHGQMgnrFmzBsePH8eePXugqqr63vsjIyPh7u6OoUOHIj4+Hrt378ZXX3313rrQ0FBs27YN1tbW\nyMzMxI4dO6CgoPDeur///huHDx+Gubk5SkpKsGnTJsjKyr63ztfXF4GBgejYsSPk5OSwZs0aSEtL\n11nDGMOePXsQFxcHBQUFdOzYEcuXL4eEhESddXw+H5s3b8bz589RXFyMvn37Yu7cue+tq6mpgZub\nG3g8HjIyMjBq1ChMnjz5vWzV1dVYuXIllJWVcfr0acjIyNT/xSXkfySokMmnMMagqKiINWvWYPDg\nwR9cd/v2bVy6dAnLly+vt4zfCQ0Nxa1bt7B8+fJ6y/id8+fP49GjR/jpp5/qLeN3/Pz8kJOTg8WL\nF79Xxv/+HLy9vVFVVVVvyb7D5/Oxb98+KCoqYvr06R9cV1NTg507d0JbWxsTJkz4YLasrCxMnDgR\nd+/ehZmZ2QfXEQJQIZMGCgsLw4QJE7Bx40b06NGD6zgtwvPnzzF//nz88ssvWLRoEddxSAsgyXUA\n0jIMGjQIJ0+exMqVKxEfH891HKFHZUy+BBUyaTAq5YahMiZfigqZfBYq5Y+jMiaNQYVMPtugQYPg\n6OiIM2fOcB1F6Fy5cgWqqqqYO3cu11FIC0SFTD7bmjVrEBkZiZ9++onrKHWUlpYiODgYvr6+SEhI\n+KyP9fX1hb+/f6MzTJo0CcrKyhg3bhzevHnT6OMR8UJnWZDP8qnzkbl05swZODo6ori4GBUVFdDX\n12/wx5aUlEBSUhKKioqNzkHnH5MvRRMyaTBhLmMAePXqFRQUFKChofFZZQwAVVVVqKqqapIcsrKy\n2LhxI4qKimhSJp9Fyt3d3Z3rEET4NbSMr127Bj8/P1RUVCA4OBi9evVCTU0Nzp07h5KSEkRFRcHU\n1LTej+Xz+Th9+jTy8/Oxbds2ODo6YseOHejYsSMkJCTw+++/w9bWFjdv3oS3tzekpaVx8uRJqKqq\noqioCLdu3YKSkhKqqqrQtm1b3L59G+np6cjOzkZGRgb09PSQnZ2NsLAwZGVlITc3F7q6usjPz0dg\nYCBkZWXRoUMHVFRUwNXVFVVVVXj06BHy8/PRsWNH3L9/H0lJSQgNDUV4eDjMzMwgLy9f7+ciJSUF\nW1tbXLx4EQEBARg7diykpKSa5HtBRBdNyOSTGGPYsmULZs2a9cnJuHPnztDT04OdnR00NTXx4sUL\nBAQEoEePHujbty80NDQQGRlZ78eWl5cjOzsbNjY2WLZsGQDA0NAQAKCkpIQOHToAAKysrMDn82Fi\nYoLFixfDyMgIhoaG0NTUhKWlZe10LCkpCWtra5iYmCAxMREAcOzYMYwYMQI2NjYoLy8HALRv3x7d\nunWrzdGqVSt06NABdnZ2GDVqFB4/fgwAiIuLg42NDWxsbNC9e/ePXo0IvJ2UFy9ejEuXLiElJeWj\nawkBqJBJA0hISCAgIABbtmxp0KluSkpKAAAZGRnU1NQgJSUFurq6AAAdHZ0PlpOSkhJ69+4NV1dX\npKWlfXSPDh06QEFBAdu3b0dlZSUKCgpQWlpaZ420tDTOnj2LgoKC2um0srISUlJSkJeXh52d3QeP\nLycn995rvxISEmCMoby8HO3bt//4FwFvT4FbsmQJtm3bRpdNkwahQiYN0pjzjw0MDJCbmwsAyM3N\nRadOnepdl5mZCUtLS6xfvx7JyckoLS2FjIwMeDweAKC4uLh2bXV1NRYtWoSamhooKCjg3r17CA8P\nx79/R33x4kU4OTnBxMQEEhISqKmpgbS0dO2az51a27dvj4iICJSXl+Prr7/+6Fo6H5l8ifrvxEJI\nPd6V8sfuaZGenl473aalpUFZWRkjR45EQEAAnj17hpycHIwaNare41dVVcHDwwPDhg1Dhw4doKio\nCHNzc3h7e8PMzAyVlZXIzs7G06dPce7cOVhYWOC3336DhIQEjIyMUFJSgr/++gtOTk5QVlaGjo4O\nLl++DFlZWbx+/RqpqakYO3YsDh06hA4dOkBTUxMAkJeXh4cPH4IxBh0dHbRp0wZpaWnIycmp/Twq\nKiqQnZ2NoqIiSEtLo1WrVujevXu9nweVMflSdNob+Wxc3mioqKgICxcuhIWFBVxcXOrcjS0kJATH\njh3D4cOHP3iXtsY4ePAgZs2aBR6PB09Pz3rPw6YyJo1BL1mQz8bVlXqvXr3CvHnz0Lt37/fKGAAG\nDx6Mqqoq3Lx5UyD7q6mp4fbt24iJiUHPnj3rXUNX6pHGoAmZfDYuzkcuKCjA/PnzMXDgQDg7O39w\nAr527Rq8vLxw9OhRSEo2/7xBF4WQxqAJmXwWLso4Pz8fzs7OsLOz++jN5QHA2toaUlJSCA8Pb5Zs\n/0UXhZDGoEImDcZFGefm5mLOnDkYMWIEZs2a9cn1EhISmDt3Lg4cOFB7dkZzo1ImX4oKmTQIF2Wc\nnZ2NOXPmYPz48Zg+fXqDP65fv35QUlLClStXBJju46iUyZegQiaf1JAr9Rhj2L17N2xtbfHw4cMP\nHovP52PDhg2ws7P76MUfGRkZmDhxIkpLSzFgwIAPrquqqsKSJUswbtw4FBQUAHg7Jc+bNw9eXl6o\nqakBAJSVlWHWrFmYNm0aXr9+/cHjFRUVYcqUKXB2dq69kq8++fn5cHJywrJly1BdXV3vGrpSj3wu\nKmTySZ+6Uo8xhr179yIuLg579+7Fzz//XO/tL9891TknJwebNm3CokWLkJ6e/t661NRUTJ06FQYG\nBli3bh3mz5+P7Ozs99ZVVVXhl19+gaamJn788UfMmzevtpR79eqFdu3a4dKlSygrK8PSpUthaWkJ\ne3t7LFq0qM5FJu+8O6Xuu+++Q7du3eDi4oKKior31uXn52P+/PmYPXs21NTU8Ouvv9ZbynSlHvls\njJAGCg0NZaqqqszLy4vFxsay2NhYFhMTw2bMmMG6du3KXrx4wRhjLCAggKmpqbEjR47UWTdu3DjW\nt29fVlxczBhj7OjRo6x9+/bs1KlTteuOHTvG5OTkmJmZGauoqGCMMbZ7926mpaXFLly4ULvu9u3b\nrH///mzs2LHszZs3jDHGPDw8mIGBAQsODmaxsbHs4MGDTENDg1lYWLCZM2cyHo/H+Hw+W7JkCTMz\nM2NXr16tPV5YWBjr0qUL+/nnnxmfz2c8Ho9Nnz6d9erVi924caN2XVBQENPX12cbN25kjDFWXV3N\nRo4cyaytrVlkZGTtugsXLjBtbW22a9cuDr5TpKWiQiaf5d+lHBMTw2bOnMnMzMxYfn5+nXUXLlxg\nqqqqzMfHh8XExLDx48ez3r17s9evX9dZ5+vry9TV1dnp06eZj48Pk5WVZWZmZqy8vLzOul27djFt\nbW0WEBDAbt++zQYMGMBGjx7Nqqur66xbu3Yt69SpE7t8+TK7fv06a9OmDfvmm28Yj8erXcPn89ni\nxYtZ165dWXh4eG0Zu7i4MD6fX7uOx+OxadOmsd69e7ObN2+y4OBgpq+vz37//fc6e1ZVVbERI0Yw\nW1tbFhkZSWVMvhgVMvls70r5u+++Y6ampu+V8Tvnz59nampqzN7envXq1YsVFRXVu+7IkSNMRUWF\nycjIsK5du75Xxu/s3LmTaWtrs2+//ZaNGjXqvTJ+Z82aNczQ0JBZWlqyYcOGMW1t7dpp+x0+n88W\nLlzIunXrxkxNTdmyZcvqlPE7NTU1bMqUKaxXr15MX1+frV+/vt49q6qq2HfffccGDBhAZUy+GN0P\nmXw2AwMD9OzZE/Hx8Th9+vQH73xmbGwMY2NjpKWl4dSpUx+8XWV5eTmOHDmCb775BlevXoWCgkK9\n6/r06QM5OTkAgLe39wcvurCxsUFFRQXU1NTg7e2NiIgIFBYWok+fPrVrJCQk4ODggOfPn6Nr167Y\nuHFjvec3S0pKYuTIkUhKSsKgQYPw66+/1runlJQUxo4dizt37mDChAlYsGBBvesI+Ri6Uo9w6vr1\n63BycoKPjw+GDh0qkD3u3bsHBwcHpKenf7DsCREGdJYF4UxYWBjGjh0LPz8/gZUxAJibm8PKygp7\n9uwR2B6ENAWakAknLl++jKlTp+L06dOwtrYW+H6PHj2Cra0t0tLS0Lp1a4HvR8iXoAmZNLuAgABM\nnToV/v7+zVLGAGBqaoohQ4Zg586dzbIfIV+CJmTSrM6dO4d58+YhICAAvXv3bta9U1NT0a9fP6Sk\npKBt27bNujchDUETMmk2J0+exPz58xEUFNTsZQwARkZGGDFiBLZv397sexPSEDQhk2bh6+uLFStW\n4PLly3We8Nzcnjx5gp49eyI5ORlqamqc5SCkPjQhE4E7dOgQVq5cidDQUE7LGAD09PQwfvx4/PHH\nH5zmIKQ+NCETgdq/fz82bNiA0NBQdO7cmes4AN7e1rN79+5ITEyEhoYG13EIqUWFTARm165d2L59\nO65evQoDAwOu49SxdOlSAICnpyfHSQj5/6iQiUBs2bIF+/fvx9WrV9GxY0eu47wnNzcXZmZmuH//\nPrS1tbmOQwgAKmQiAOvXr4evry/CwsKEuuxWrFiB4uJi7Nu3j+sohACgQiZNiDGGNWvW4OzZswgN\nDYWmpibXkT6qoKAAxsbGiI2Nhb6+PtdxCKFCJk2DMYaVK1fi0qVLCA0N/eAd4ISNm5sbsrOzcejQ\nIa6jEEKFTBqPMQYXFxdERETgypUrzfYQ1KZQVFQEIyMj3Lp1S2jOAiHii85DJo3C5/OxcOFC3L59\nG2FhYS2qjAFAWVkZS5Yswdq1a7mOQghNyOTL8fl8ODs749GjRwgKCkKbNm24jvRFSkpKYGhoiKtX\nr9LDSAmnqJDJF+HxeJgxYwaysrIQGBgIJSUlriM1ypYtWxAdHY0zZ85wHYWIMSpk8tlqamowbdo0\nvHjxAufPnxeJp3CUl5fD0NAQly5dgrm5OddxiJii15DJZ6mursbEiRNRWFiICxcuiEQZA4CCggJ+\n/fVXuLm5cR2FiDGakEmDVVVVYdy4cZCQkMCpU6dqHzgqKiorK2FkZIQzZ87UeSAqIc2FJmTSIBUV\nFRg1ahRkZWVx+vRpkStjAJCXl8fq1atpSiacoUImn1ReXo7vvvsObdu2xYkTJyArK8t1JIH58ccf\nkZKSghs3bnAdhYghKmTyUaWlpXB0dISWlhZ8fX0hLS3NdSSBkpWVhZubG1xdXUGv5pHmRoVMPuj1\n69ewt7eHkZERvL29ISUlxXWkZjF16lQ8f/4cV69e5ToKETNUyKRehYWFGDJkCMzNzXHgwAFISorP\nj4q0tDTc3d2xevVqmpJJsxKf/8tIg718+RKDBg2ClZUVdu/eLVZl/M6ECRNQUlKCoKAgrqMQMSJ+\n/6eRj8rPz4etrS3s7Oywbds2SEhIcB2JE1JSUli7di29lkyaFRUyqZWTkwMbGxuMHj0aGzduFNsy\nfmf06NHg8/nw9/fnOgoRE3RhCAHw9sGfAwcOxPTp0/Hbb79xHUdoBAYGYuXKlbh//75YvnRDmhf9\nhBFkZWXB2toac+bMoTL+j2HDhkFRURGnTp3iOgoRAzQhi7mMjAwMHDgQLi4uWLx4MddxhFJISAgW\nL16MhIQEkT8Pm3CLJmQxlpKSAhsbG/z6669Uxh8xZMgQtG/fHsePH+c6ChFxNCGLqUePHsHOzg5r\n167FzJkzuY4j9CIiIjBjxgwkJSVBRkaG6zhERNGELMIYY3j06BFKS0vrvP3BgwcYPHgwNm3aRGXc\nQNbW1jAwMMDhw4e5jkJEGE3IIiozMxN+fn5QUVFBfn4+VqxYATk5OcTHx8PR0RE7d+7EhAkTuI7Z\nYhQWFiIsLAwuLi5ISUmBvLw815GICKIJWUQxxlBTU4O5c+eidevW8PPzw/nz5+Hg4IB9+/ZRGX+m\nf/75BwEBAejatSsOHjzIdRwioqiQRZScnBxUVVVRVVUFJycn3L9/H9OmTYOXlxdGjx7NdbwWR1lZ\nGerq6rCwsMDGjRtRVlbGdSQigqiQRVT79u2RmZmJ1NRUZGRkwNvbG1OmTEHv3r25jtYi6erqYtOm\nTcjJycHXX3+N/fv3cx2JiCAqZBElIyODkSNHwtPTE2PHjoWPjw8UFRXpPNpGkJSUhIODAzp27Igt\nW7a898tSQhqLClmElZaWws/PDwsXLsSIESNgZGSEuLg4rmO1aOPGjUOrVq1gYWGBXbt2cR2HiBg6\ny0JEBQQEYObMmTh+/DhKS0sRGRkJXV1dDBs2DHp6elzHa9GuXbsGZ2dn5OXlISsrC1999RXXkYiI\noEIWQWfPnsX8+fMRGBiIXr16AXh77rGZmZnYPPVDkBITExEYGIjExEQYGBjA3d2d60hERFAhixg/\nPz+4uLggKCgI5ubmXMcRaRkZGejVqxdSUlKgqqrKdRwiAug1ZBHi4+ODn376CVeuXKEybgYGBgZw\ncnLC1q1buY5CRARNyCLir7/+wpo1axAaGgoTExOu44iNf/75B927d8fjx4+hrq7OdRzSwlEhi4C9\ne/di8+bNCA0NhZGREddxxM6iRYsgIyOD7du3cx2FtHBUyC2cp6cndu7ciatXr0JfX5/rOGIpJycH\nZmZmePjwIbS0tLiOQ1owKuQW7I8//oCXlxeuXr0KXV1druOItZ9//hkVFRXYs2cP11FIC0aF3EJ5\neHjg2LFjCAsLo6lMCLx48QImJiaIj49Hx44duY5DWigq5BaGMQY3NzecO3cOYWFh0NDQ4DoS+Z/f\nfvsNeXl5dDc48sWokFsQxhhWrFiBy5cvIzQ0FO3ateM6EvmXV69eoXPnzoiKioKhoSHXcUgLRIXc\nQjDGsGzZMty4cQMhISF0IYKQWrduHdLS0uDj48N1FNICUSG3AHw+HwsXLkR8fDyCg4OhrKzMdSTy\nAcXFxTA0NERERAS6dOnCdRzSwlAhCzkejwdnZ2ckJyfj4sWLaNOmDdeRyCds3rwZ8fHxOHnyJNdR\nSAtDhSzEampqMGPGjNrHBykpKXEdiTRAWVkZOnXqhMuXL6N79+5cxyEtCBWykHrz5g2mTp2KV69e\nwd/fHwoKClxHIp9hx44diIiIgL+/P9dRSAtChSyEqqurMWnSJFRWVuLs2bP0hOMWqKKiAkZGRvD3\n94elpSXXcUgLQXd7EzLvHkrK4/Fw7tw5KuMWqlWrVli1ahVcXV25jkJaECpkIVJRUYGRI0dCXl4e\np0+fhpycHNeRSCPMnDkTjx8/xq1bt7iOQloIKmQhUVZWhuHDh0NVVRXHjx+HjIwM15FII8nJycHV\n1ZWmZNJgVMhCoKSkBA4ODtDV1YWPjw89GVqETJs2DU+fPkV4eDjXUUgLQIXMsdevX8Pe3h5dunTB\nX3/9Rc+8EzEyMjJwd3eHq6sr6Pfn5FOokDlUWFiIIUOGoGfPnti/fz8kJenbIYomTZqEV69e4fLl\ny1xHIUKOGoAjBQUFGDhwIAYMGIBdu3ZBQkKC60hEQKSkpLB27VqaksknUSFzIC8vD7a2tnBwcMCW\nLVuojMXA2LFjUV1djQsXLnAdhQgxKuRmlpOTAxsbGzg5OeH333+nMhYTkpKSWLduHdzc3MDn87mO\nQ4QUFXIzys7OhrW1NaZNm4Y1a9ZQGYuZESNGQFZWFmfPnuU6ChFSdOl0M3ny5AkGDRqEBQsWwMXF\nhes4hCPBwcFwcXHBw4cP6Ywa8h6akJtBeno6bGxssGzZMipjMWdvbw8VFRX4+flxHYUIIZqQBSw5\nORmDBw+Gq6sr5syZw3UcIgTCw8Mxe/ZsPH78mK7IJHXQhCxAjx49wsCBA7Fu3ToqY1LL1ta29qpM\n4O1f2oQANCELzIMHDzB06FBs2bIFkydP5joOETK3bt3C5MmTcefOHZiamqKgoIDrSEQI0E0TBCA+\nPh6Ojo74888/MW7cOK7jECFz584dKCsro0uXLvD19cWbN2+4jkSEBL1k0cSio6Ph4OCA/fv3UxmT\nehUUFMDa2hrm5ubYtm0beDwe15GIkKCXLBqJMVZ7PvGtW7cwevRoeHt7Y9iwYRwnI8IsOTkZEyZM\nQF5eHgoKCmhKJgBoQm4UxhgsLS2Rk5ODa9euYfTo0Th69CiVMfkkY2NjREVFwdbWlq7cI7WokBsh\nLi4Or1+/RkJCAsaPH4+TJ0/Czs6O61ikGeXm5uLhw4efXJeVlYWUlJQ6b5OXl8fx48eRlZVV+7bk\n5OQ6//0hDx8+RG5u7ifXxcbGorCw8JPrbt68ifLy8k+uIwLGxFxJSQlLT0+v/VNSUtLgj3VxcWET\nJ05k7dq1Y9evX2f5+fkCTEqETVZWFtPT02NfffUVCwgI+OC6xMREpq6uzlRUVNitW7c+uO7mzZtM\nRUWFqaurs8TExA+uu3DhAvvqq6+Ynp4ee/r06QfXHTx4kCkqKrLu3buzly9ffnDd+vXrWatWrZi1\ntTUrKyv74DoieGJXyIWFhczLy4s5OjoyXV1dJi8vz7S1tZmOjg7T1tZm8vLyTFdXlzk6OjIvLy9W\nWFhY73F4PB5TVVVlSkpKbPz48UxHR4cNGDCgmT8bwpV3Zezi4sIOHz7MVFVV2cWLF99b9+jRI6au\nrs7WrVvHdu3axVRVVVlkZOR76yIjI5mqqir7888/2bp165iGhgZ7/Pjxe+sCAwOZqqoqO3LkCFu6\ndCkzMDBg2dnZ7607dOgQ09DQYGfPnmVTpkxhFhYW7NWrV++t27hxI9PT02MXL15kw4cPp1LmmNgU\n8rNnz9iUKVNY69at2eDBg9mGDRvYuXPnWHR0NIuNja39Ex0dzc6dO8c2bNjABg8ezFq3bs2mTJnC\nnj9/Xud4gYGBDAAzNjZmHh4eLDExkfH5fI4+O9Kc/l3G735uvL29maqqKgsKCqpdl5SUxDQ0NJi7\nu3vtOk9PT6aqqsqio6Nr10VHRzNVVVXm6elZu87d3Z1paGiwpKSk2nVBQUFMVVWVeXt7165bvHgx\n69SpE3v27FntuiNHjjB1dXV25swZFhsby2JiYtjkyZNZjx496gwYf/zxB+vYsSO7dOlS7c8+lTK3\nRP4sC8YY9uzZgzVr1mDkyJGYOnUq2rRp0+CPLy4uhq+vL86fP4+1a9diwYIFkJCQAI/HQ3p6Ojp3\n7izA9ETYPH36FNbW1hg7diwmTZpU533379/HL7/8guPHj0NPTw82NjaYM2cOvvvuuzrrrl+/jt9/\n/x3BwcFgjMHBwQGrV69G//7966y7cOECDh48iGvXriEjIwOTJ0/Gli1b8PXXX9dZ5+3tjZCQEERE\nRCAsLAw//fQT9uzZA319/do1jDFs27YNaWlpCA0NxcGDB7Fr1y7s27cP6urqtet4PB48PDxQUlKC\nS5cuQUFBoam+dKQBRLqQ+Xw+5syZg8jISLi7u8PAwOCLj5WRkQF3d3f069cPBw4coMctiaGCggL0\n6tWr3jJ+5969e1ixYgVkZGQwe/ZsjBw5st51ERER2LhxIwBg1apVGDBgQL3r/P39cfDgQbx58wab\nN2+Gubl5vesOHTqEgIAAVFVVYffu3fX+rDPGsHXrVkRHR4PH42Hfvn3Q0NB4b92/Szk8PJxuE9uM\nRLqQlyxZgps3b2LHjh1QVFRs9PHKysqwbNky9O/fH56enk2QkLQk2dnZMDc3x6pVq2Btbf3BdYmJ\niSgsLISVldVHjxcbGwsAsLS0/Oi6mzdvQkVFBaamph9dd+XKFRgaGtaZjP+LMYbAwED06tWr3jJ+\n5+DBgwgLC0NycjIVcjMS2UIODQ3FDz/8gKNHj6J169ZNdtySkhJMmTIFR44cwaBBg5rsuKRliI2N\nhYODA1auXPnRUm7J/vrrL4SGhiIiIgKamppcxxErIlnIlZWV6Nq1KxYsWPDBfwo2RkREBPbt24eE\nhATIyck1+fGJcBPlUj506BCuXLlCZcwRkXwh1NfXF5qamgIpYwCwtraGhoYGfH19BXJ8ItwsLS0R\nFBSEjRs3IiIigus4TebQoUM0GXNMJAvZ29sbo0ePFugeo0aNgre3t0D3IMLr36UcHR3NdZxGO378\nOEJDQ3Ht2jUqYw6JXCE/efIEycnJ6Nevn0D3+fbbb5GUlIQnT54IdB8ivNq3bw8FBQUUFRVxHaXR\nCgoKoKGhga+++orrKGJN5Ar59u3b6Nmzp8AfjSMjIwNLS0tERkYKdB8inN6dj+zk5AR7e/uPrr18\n+TLCw8Ph5+eHqKgobN++vc77ExIS4O7uLsC0n7ZgwQK0adMGjo6OdE8LDolcISckJHz0tJ+m1LFj\nRyQkJDTLXkR4vCvjMWPG4Pvvv//o2idPnkBBQQHW1tbQ19dH37593zsF08TEBAsXLhRk5E+SkpKC\nq6srWrduTaXMIZEr5MTExGYrZAMDAypkMfPvK/U+VcYA8PLlS7Rq1QqSkpLo27dvvWvevHmDioqK\npo762aiUuSdyj3CqrKxEq1atPrnu2rVriIyMRM+ePZGamorZs2fj/Pnz0NHRQXZ2NpycnD55jFat\nWqGysrIpYpMW4N2TPj52pd6/5ebm1j7AVFZW9r1LngGgoqIC8fHxSEhIgLOzMwDAw8MDxsbGaN26\nNQoLC/H999/X+7bKykr4+/tDRUUFPB4PDg4OCAkJwf3792FhYYEbN25g0aJFePnyJTIzM/H69WsU\nFRXV7lOfd6Xs4eEBR0dHulKvmYnchNxQnTt3hp6eHuzs7KCpqYnDhw+jR48e6Nu3LzQ0NOi1YfKe\nyspKlJSUoEOHDg1ar6Ghgc6dO6Nz5871ljHw9i/1b7/9ts7bzM3NYWlpCQcHB5SXlyM3N7fet/n7\n+6N///6ws7NDQkICeDwe7OzskJeXBysrK6xcuRKqqqq4e/cu9PT0MGHCBAwePPiTuaWkpKCtrY3n\nz5836PPnes80AAAa8UlEQVQkTUfkCllaWrrBj8NRUlIC8PYXdAkJCdDV1QUA6OjovHcz8fq8efNG\n4L88JMJDW1sbwcHBzXL+sby8PACgqKgIUVFRSExMrH0ytYqKCgoKCpCZmYlnz54hNjYWHTp0qH3Z\nw8jICPLy8pCXl4eEhATGjBmDiIgIrF27tkEXMv31118ICwtDREQETcfNTOQK2djYuEFPXPgvKyur\n2icw5ObmolOnTp/8mCdPnsDExOSz9yItV3NdFMLn81FdXY2AgACoqamhrKwMhw4dAgDk5eVBU1MT\n2tra0NLSgqWlJezt7WsHjP9KT0+Hs7MzfvnlF5w+ffqj+9LFIdwSuULu1q1bg84NTk9PR1paGgAg\nLS0NmpqaiI6ORlRUFJ4/f/7ePyPr8+TJE3Tt2rWxkUkL09BSfv36NR4+fIgHDx7g6dOnqKqqQlRU\nFFJTU3Hv3j0Ab19DvnnzJp48eVL78wgA4eHh2LBhAzQ0NGBlZYUePXogKSkJXl5eaNeuHVRVVTF6\n9GgEBQUhKCgIjx8/BgBERUUhLS0NDx48qD1WSEgITp06hbt376Jnz54fzEtlzD2Ru5dFYmIi7Ozs\n4O/vL9BbZPL5fIwcORJXrlyBmZmZwPYhwuvdPS3Wrl2LPn36NNlxAwIC0LVrV8yfPx/bt29Hly5d\nEBAQgBcvXiA2NhZ79+5tsr3eOX78OAIDA+lKPY6J3IRsZmaGtm3b4u7duwLdJz4+HioqKlTGYkxQ\nV+qlpKTg0KFD6Nq1K7p06VL7NnV1dTx79gxxcXFNuh9AV+oJC5ErZACYPn06AgICBLpHQEAApk+f\nLtA9iPD6nCv1Pte8efMQHR1d5/S0n376CcOGDcPs2bOxf/9+NPU/bOlKPeEgkoU8a9Ys3LlzR2AX\nbSQkJCAmJgazZs0SyPGJcPucK/W+xMmTJ2FpaQlDQ8P33jd06FC8evWqyW9oRBeFCAeRLOS2bdti\n69at2Lx5M2pqapr02DU1Ndi8eTO2bduGtm3bNumxifD73Cv1PldpaSmOHTuGOXPm1Pt+aWlpzJkz\nB/v27WvyKZlKmXsiWcgAMGXKFBgaGmLdunXg8XhNckwej4d169bB0NAQkydPbpJjkpajoVfq5eXl\nISMj45PHy87ORnZ2dp23HTt2DN9++y309PRq35aRkYG8vLza/x4yZAgqKytx8+bNOh+blJSEwsLC\nT+778OFDlJaW1vu+/5ayiP3OX+iJbCFLSEjg5MmTqKiowMqVK/H69etGHe/169dYuXIlKioqcPLk\nSTphXgw15Eq97OxszJo1C87Ozrhz584H1yUlJWHWrFmYNWsWkpKSALy9COTUqVOYPXt27bp3ryXP\nmjWrtrwlJSUxd+5c7N+/H3w+H8DbU9vmzZuHuXPn4uXLlx/c98SJE1iwYAGWLl2KsrKyetfQlXrc\nEdlCBt5elhoUFAQTExNMnDgRFy9erP0Bbig+n4/AwEBMmDABJiYmCAoKatC9Mojo+dSVetnZ2Zg/\nfz7c3Nzg7++P1atX1z7I9N+SkpKwdOlSeHl5Yf/+/Vi2bBmSk5Nx9OhRDBw4ENra2gCAmJgYuLq6\nwt/fH66urpg/f35tKdvY2EBCQgLh4eEIDQ2Fp6cnbt26hcmTJ2PhwoV49erVe/uePn0ap06dQmJi\nIiwtLT9YynSlHoeYmLhz5w6ztLRkWlpabMaMGez48eMsKiqKxcbGvvcnKiqKHT9+nM2YMYNpaWkx\nS0tLFhMTw/WnQIRETEwMU1NTY9u2bav9mblw4QLT0tJiu3fvrl0XHh7OVFRU2IEDB2rXHT9+nKmp\nqbHTp0/Xrjt16hRTUVFhSkpKLDAwkMXGxrIDBw4wFRUVFh4eXrtu9+7dTEtLi124cIHFxsYyT09P\npq6uztTU1Ni9e/cYY4zx+Xy2atUqZmRkxEJDQ2v3/fXXX5m2tjbLyMhgjDHG4/HYjBkzWM+ePdn1\n69dr182fP58ZGRmx58+fN88Xk9QhNoXM2Nsf1rt377KlS5cyAwMDJicnx4yNjZmVlRXr378/s7Ky\nYsbGxkxOTo4ZGBiwpUuXsrt37zI+n891dCJk/l3KAQEBTFtbm+3ateu9daGhoUxFRYX93//9Hztx\n4gRr164dO3ny5HvrHB0dmby8PDtx4gTz8vJiKioqLCws7L11O3fuZNra2iwgIID98ccfTFpamm3Y\nsKHOGj6fz1asWMGMjY1ZaGgoW7VqFdPS0mJpaWl11vF4PDZ9+nRmaWnJbty4QWUsBMSqkP+rrKyM\nxcXFsYsXL9b+iYuLY2VlZVxHIy3Au1LW0NBgnp6eH1x35coVpqKiwtq1a8f8/Pzee/+zZ89Y27Zt\n2Z49e1i7du2Yqqoqu3LlygePt2PHDqahocHU1NTY3r17mZGREXvz5k2dNXw+ny1fvpx16NCBaWlp\nsdTU1HqPxePx2NSpU5m2tjaVsRAQuUunCWlO9+/fR0ZGxicfqnv79m2UlpbCzs7uvfctXLgQ8vLy\n2Lp1K0JCQqCkpPTJZ0L+/fffMDAwwNdffw1bW1v88MMP+OGHH+qsYYzh2LFj6Nu3b73nNL/D4/Fw\n6NAhDB8+nC6b5hgVMiEcysrKqr1xULt27b7oGDdu3MC0adOQnJwMWVnZJk5ImpNIn2VBiLBbv349\n5s6d+8VlDAD9+/eHkZERvL29mzAZ4QJNyIRwJC0tDX379kVKSgpUVFQadazo6Gg4OTkhNTW19ub2\npOWhCZkQjqxbtw6LFi1qdBkDQJ8+fWBubg4vL68mSEa4QhMyIRx4/PgxrK2tkZqa2mS3vLx79y6G\nDRuGtLQ0KCgoNMkxSfOiCZkQDri7u8PFxaVJ7z9sYWGBfv36Yc+ePU12TNK8aEImpJk9ePAAdnZ2\nSE9Ph6KiYpMeOzExEQMHDkRaWhpat27dpMcmgkcTMiHNzM3NDStWrGjyMgbePjFn8ODB2LVrV5Mf\nmwgeTciENKPY2FiMHDkSaWlpArtJVUpKCvr164e0tDQoKysLZA8iGDQhE9KM3Nzc8Ntvvwn0joGd\nO3fGd999h+3btwtsDyIYNCET0kxu376NSZMmISUlBXJycgLdKzMzE5aWlkhOToaamppA9yJNhyZk\nQpqJq6sr3NzcBF7GAKCvr49x48Zhy5YtAt+LNB2akAlpBuHh4Zg9ezYeP34MGRmZZtkzOzsb3bt3\nR2JiIjQ0NJplT9I4VMiECBhjDP3794ezszOmTp3arHsvWbIEEhIS8PT0bNZ9yZehQiZEwC5fvoyl\nS5ciISEBUlJSzbp3bm4uTE1N8eDBg9pHQxHhRYVMiAAxxtC7d28sX74c48eP5yTDL7/8gtLSUuzd\nu5eT/UnDUSETIkAXLlyAq6sr7t69C0lJbn6HXlBQAGNjY8TFxUFPT4+TDKRh6CwLQgSEz+fD1dUV\n69at46yMAUBNTQ3z58+Hh4cHZxlIw1AhEyIgZ8+ehaysLEaMGMF1FLi4uOD8+fNITU3lOgr5CHrJ\nghAB4PF46NatG7Zv346hQ4dyHQcA4OHhgeTkZBw9epTrKOQDaEImRAD8/PzQtm1b2Nvbcx2l1pIl\nSxASEoJHjx5xHYV8AE3IhDSxN2/ewNTUFF5eXrC1teU6Th1//PEHYmJicPr0aa6jkHrQhExIE/Px\n8YGOjo7QlTEALFiwADdv3sS9e/e4jkLqQRMyIU2ouroanTt3xrFjx/Dtt99yHadeO3fuxNWrV3H+\n/Hmuo5D/oAmZkCb0119/oUuXLkJbxgDg7OyM+Ph43Llzh+so5D9oQiakiVRUVMDIyAh///03evXq\nxXWcj9q/fz/8/f0RHBzMdRTyLzQhE9JEDhw4AEtLS6EvYwCYMWMGkpOTcfPmTa6jkH+hCZmQJlBW\nVoZOnTohJCQEX3/9NddxGuTQoUPw9fVFeHg411HI/9CETEgT2L17NwYMGNBiyhgApk2bhuzsbFy9\nepXrKOR/aEImpJGKi4thaGiIiIgIdOnShes4n+XYsWPYs2cPbt26BQkJCa7jiD2akAlpJE9PT9jb\n27e4MgaAiRMn4vXr1/TLPSFBEzIhjVBYWAgjIyNERUXB0NCQ6zhf5MyZM9i0aRNiYmJoSuYYTciE\nNMLWrVsxatSoFlvGADBmzBjU1NTQhSJCgCZkQr7QixcvYGJigvj4eHTs2JHrOI0SEBCA3377Dffu\n3eP03s3ijr7yhDQQYwyPHj1CaWkpgLc36pk4cWKLL2MAGD58OFq1akU3HeIYTciENEBmZib8/Pyg\noqKC/Px8TJs2DT169MDDhw+hpaXFdbxGKywsxPnz57F582Y8fPgQ0tLSXEcSSzQhE9IAjDHU1NRg\n7ty5aN26NWbPno3Ro0eLRBkDwD///IPw8HCoqKjAz8+P6zhiiwqZkAaQk5ODqqoqqqqq8M033+DW\nrVuwsrICj8fjOlqTUFZWhrq6Ovr27Qt3d3dUV1dzHUksUSET0gDt27dHZmYmUlNT4e3tjeHDh6O8\nvBz5+flcR2sSurq62LRpEwoLC6GpqQkfHx+uI4klKmRCGkBGRgYjR46Ej49P7Xm7WVlZIvVaq6Sk\nJBwcHGBsbAwPDw9UVVVxHUnsUCET0kBWVla4cuUKbG1tYWBgACMjI8TFxXEdq0mNGzcObdq0ga6u\nLg4ePMh1HLFDhUxIA6WkpODp06cYPXo0VqxYgerqapiYmHAdq8mNHDkSubm5WLNmDSoqKriOI1ak\n3N3d3bkOQUhLsHjxYowaNQoLFiyAuro6HB0doaKiwnWsJldWVgYlJSVISEjgxYsX+Oabb7iOJDbo\nPGRCGiAhIQGDBg1Ceno6lJSUuI7TLB4+fIghQ4YgLS1NbD5nrtFLFoQ0wJo1a/DLL7+IVTF169YN\nNjY2+PPPP7mOIjZoQibkE+Lj4zF8+HCkpaVBQUGB6zjNKikpCQMGDEBqaiq++uorruOIPJqQCfkE\nNzc3rFy5UuzKGABMTEzg4OAAT09PrqOIBZqQCfmIqKgojB8/HqmpqZCTk+M6DifS09PRp08fpKSk\niOQvMYUJTciEfISrqytWr14ttmUMAJ06dcKYMWOwdetWrqOIPJqQCfmA69ev44cffkBycjJkZGS4\njsOpp0+fwsLCAo8fP0b79u25jiOyqJAJqQdjDNbW1pg5cyamT5/OdRyhsGjRIsjKymLbtm1cRxFZ\nVMiE1OPKlStYuHAhEhMTRep+FY2Rk5MDMzMzJCQkoEOHDlzHEUlUyIT8B2MM33zzDZYuXYqJEydy\nHUeo/Pzzz6isrMTu3bu5jiKSqJAJ+Y/AwECsXLkS9+/fp+fL/ce75wjevXsXurq6XMcROVTIhPwL\nYww9e/bE6tWrMWbMGK7jCKVVq1ahoKAAXl5eXEcROfTXPyH/8vfffwMARo8ezXES4fXzzz/j3Llz\nSE9P5zqKyKEJmZD/4fF46N69OzZv3oxhw4ZxHUeorV27FhkZGThy5AjXUUQKTciE/M+pU6egpKQE\nR0dHrqMIvaVLlyIoKAhJSUlcRxEpNCETAqCmpgampqbYu3cvBg8ezHWcFmHTpk24d+8eTpw4wXUU\nkUETMiEAjh49Ck1NTQwaNIjrKC3GwoULce3aNTx48IDrKCKDJmQi9t49iunw4cMYMGAA13FalB07\nduD69eu1vwwljUMTMhF73t7eMDQ0pDL+AnPnzkVMTIzIPeyVKzQhE7FWWVkJIyMjnDlzBn369OE6\nTou0d+9eBAYG4tKlS1xHafFoQiZi7f/+7/9gbm5OZdwIM2fORGJiIiIjI7mO0uLRhEzEVnl5OQwN\nDXHx4kVYWFhwHadFO3jwIE6cOIHQ0FCuo7RoNCETsbV3717069ePyrgJTJ8+HU+ePMG1a9e4jtKi\n0YRMxFJJSQkMDQ1x9epVmJmZcR1HJPj6+sLLywvXr1+HhIQE13FaJJqQiVjatWsXBg0aRGXchL7/\n/nsUFBQgJCSE6ygtFk3IROwUFRXByMgIt27dQufOnbmOI1JOnTqFrVu3Ijo6mqbkL0ATMhE727dv\nx/Dhw6mMBcDJyQlVVVUIDAzkOkqLRBMyESsFBQUwNjZGbGws9PX1uY4jks6fP481a9YgPj6ebvD/\nmeirRcTKli1bMG7cOCpjARoxYgRkZGRw7tw5MMbw+PFjriO1GDQhE5F39+5dXL58GT/++CO6dOmC\n+/fvQ0dHh+tYIi04OBg//fQTAgICMGTIELqZfQPR43SJyEtPT0dMTAzy8vIwdepUKmMBu3HjBvT1\n9aGsrIyAgAC8efOG60gtBr1kQUQej8dDdXU1jhw5goEDB8LY2BjPnj3jOpbIysvLg5WVFQYMGABP\nT0/weDyuI7UYNCETkcfn8/H48WOYmprC2dkZBw8ehJaWFtexRJaTkxOMjY0xYcIElJSU0IT8GWhC\nJiIvLy8P6enpYIwhLi4Ow4cP5zqSyOvWrRtiYmLQr18/VFZWch2nxaBf6hGRFxISgqNHj8Lb2xtS\nUlJcxxE7OTk50NTU5DpGi0CFTFqkkpISPHr0CI8fP0ZFRQUAQFpaGkZGRjAzM0O7du04Tkjqw+Px\n8Pz5c2RkZODJkycoLy+vfZ+kpCS0tLSgr68PfX19KCgocJiUG/QaMmkxnj9/jmPHjsHHxwfp6eno\n1KkT9PT00KpVKwBvH8X0zz//IC0tDcrKyvj+++8xbdo0dOnShePk4osxhgcPHuDSpUsIDAxEXFwc\nlJWVoaWlBU1NzTqly+PxkJ+fj+fPn+PZs2fQ1NTE0KFDMWzYMNja2kJRUZHDz6R50IRMhF5xcTFW\nr14NHx8f2NraYujQobCwsPjgyw+MMaSlpSEoKAjBwcHo06cPdu/eDV1d3WZOLr4YY7hw4QJWrVqF\n0tJS9OvXD9988w169OhR+xfox/D5fGRkZOD27duIjo5GUlISFixYgOXLl0NZWbkZPgNuUCEToRYa\nGopp06ahb9++WLBgwWf/z1hdXQ0fHx+cPHkSGzZswNy5cwWUlLyTlJSEadOmobi4GHPnzoWVlVWj\nbzSUk5ODgwcP4ubNm1i/fr3Ifh+pkInQ8vf3x+zZs7F+/XpYWlo26lhPnz6Fi4sLfvzxR7i5uTVR\nQvJfcXFxcHBwwMyZMzFmzJgmv5dFZmYmVqxYgfHjx2Pjxo1NemxhQIVMhFJ0dDSGDRuGnTt3wsTE\npEmO+fLlSzg7O2P16tWYOXNmkxyT/H/Z2dno2bMnli9fDltbW4HtU1RUhHnz5mHx4sVYuHChwPbh\nAhUyETo1NTWwsLDApEmTYG9v36THTk9Px7x585CYmAgNDY0mPba4GzNmDNTU1ODs7Czwvf755x/M\nmDFD5O5LQheGEKGzc+dOtG7dGnZ2dk1+7E6dOmHEiBFYtmxZkx9bnAUFBSEuLg4//PBDs+yno6OD\n8ePHY9GiRc2yX3OhCZkIFR6PB21tbezYsQNGRkYC2aOiogLDhw9HQkICtLW1BbKHuLGxsYG9vb1A\n/hL9kKqqKowYMQLR0dHo1KlTs+0rSDQhE6ESHh4OFRUVgZUxALRq1QoDBw7EsWPHBLaHOMnOzsb9\n+/dhbW3drPvKyclhyJAh8PX1bdZ9BYkKmQgVPz+/Zpmy7O3t4efnJ/B9xMGpU6dga2sLOTm5Zt97\n6NChOHHiRLPvKyhUyESoxMXFoXv37gLfp2vXrkhOTqY7kTWB2NhYdOvWjZO9TUxMkJWVVecS7JaM\nCpkIDR6Ph5SUlGZ5vJK8vDw0NDSQmpoq8L1EXWJiIgwMDDjZW1paGnp6eiLzmCgqZCI08vLyoKio\nCCUlpWbZT1dXF2lpac2ylyjLzMzk9NQzHR0dkfk+UiETocHn8yEt/en7XV27dg0bN25ESEgI9uzZ\ng+rqapw+fRpRUVE4c+ZMg/eTlpYGn89vTGSChn/fEhISsGjRItTU1OD3339HSkoK/P39cfXqVfj4\n+NQe69SpUwgPD2/wRR+i9H2kQiYtTufOnaGnpwc7Oztoamri8OHD6NGjB/r27QsNDQ1ERkZyHZHU\no2vXrtDX14e0tDT69OkDCQkJSEpKYuDAgVBVVcXDhw9RXl6O7Oxs2NjYiOW54lTIRGgoKiqipKQE\nDTk1/t3LGjIyMkhISKi9k5uOjg5SUlIatF9JSUmzvTwiyt593xqiY8eOyMrKQqtWrZCZmYni4mLE\nxsZCSkoKEhISUFJSQu/eveHq6trglyFE6ftIhUyERtu2baGoqIi8vLzP+jgrKyvk5uYCAHJzcxt0\nkcC7W3SamZl9UVby/3Xp0gWZmZkNWmttbY0DBw6ge/fu0NbWRps2bWBpaYmBAwdCR0cHmZmZsLS0\nxPr165GcnIzS0tJPHjMjI0Nkvo9UyESomJmZfXIySk9Pr12TlpYGTU1NREdHIyoqCs+fP8e33377\nyX1evnwJAHQ/iybw9ddfIz09vUFr1dTUoKmpCSUlJZiamqK4uBiBgYEICQmBoqIiqqqq4OHhgdu3\nb6NDhw6fvCl9aWkpioqKoKen1wSfCffo0mkiVNavX48HDx5gxYoVAt3H398fDx48wPnz5wW6jzj4\n+++/sWnTJuzdu7dB669duwYbG5sm2Ts4OBgREREICQlpkuNxjSZkIlSmTJmC0NBQgV+wERwc3Gw3\nwhF1jo6OSEtLQ05OzkfXpaSkYOXKlejatWuT7S1q30eakInQsba2xsCBAzF8+HCBHD81NRWLFi1C\ndnY2J5f7iqK5c+eisrKyWe++9uTJE8yePRvZ2dki80BUmpCJ0NmyZQv27NmD4uLiJj82n8/H5s2b\n4eHhQWXchNzc3HDhwgVkZGQ0y36MMWzZsgWurq4iU8YAFTIRQr1798aYMWOwY8eOBp0C9zlOnToF\nWVlZzJkzp0mPK+46dOgAd3d3bNy4EdXV1QLf7/z586ioqKD7IRPSHIqLizFgwABYWFhgwYIFjX5I\nJvD29cY///wTN27cEOjtPcUVj8fDmDFjUFZWBg8PD8jKygpkn7CwMGzduhXXrl2DqampQPbgChUy\nEVovXryAvb091NXV4eLiAhUVlS86TmVlJQ4fPoyLFy/i8uXLnN2ZTBxUVlbi+++/R3p6OhYvXgxz\nc/MmO3ZRURGOHDmCK1eu4OLFi+jRo0eTHVtY0EsWRGi1a9cON27cgKmpKSZNmoSTJ0826EKBd968\neYOwsDB8//33ePXqFWJiYqiMBUxeXh6nT5/GkiVL4O7uDhcXF0RFRX3xyxiMMWRlZeHAgQNwcnKC\ngoIC4uPjRbKMAeD/AX5SwvZVtH4+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb360b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotMidText(cntrPt, parentPt, txtString):\n",
    "    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0]\n",
    "    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1]\n",
    "    createPlot.ax1.text(xMid, yMid, txtString, va=\"center\", ha=\"center\", rotation=30)\n",
    "\n",
    "def plotTree(myTree, parentPt, nodeTxt):#if the first key tells you what feat was split on\n",
    "    numLeafs = getNumLeafs(myTree)  #this determines the x width of this tree\n",
    "    depth = getTreeDepth(myTree)\n",
    "    firstStr = list(myTree.keys())[0]     #the text label for this node should be this\n",
    "    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)\n",
    "    plotMidText(cntrPt, parentPt, nodeTxt)\n",
    "    plotNode(firstStr, cntrPt, parentPt, decisionNode)\n",
    "    secondDict = myTree[firstStr]\n",
    "    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__=='dict':#test to see if the nodes are dictonaires, if not they are leaf nodes   \n",
    "            plotTree(secondDict[key],cntrPt,str(key))        #recursion\n",
    "        else:   #it's a leaf node print the leaf node\n",
    "            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW\n",
    "            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)\n",
    "            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))\n",
    "    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD\n",
    "#if you do get a dictonary you know it's a tree, and the first element will be another dict\n",
    "\n",
    "def createPlot(inTree):\n",
    "    fig = plt.figure(1, facecolor='white')\n",
    "    fig.clf()\n",
    "    axprops = dict(xticks=[], yticks=[])\n",
    "    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)    #no ticks\n",
    "    #createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses \n",
    "    plotTree.totalW = float(getNumLeafs(inTree))\n",
    "    plotTree.totalD = float(getTreeDepth(inTree))\n",
    "    plotTree.xOff = -0.5/plotTree.totalW; plotTree.yOff = 1.0;\n",
    "    plotTree(inTree, (0.5,1.0), '')\n",
    "    plt.show()\n",
    "\n",
    "#def createPlot():\n",
    "#    fig = plt.figure(1, facecolor='white')\n",
    "#    fig.clf()\n",
    "#    createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses \n",
    "#    plotNode('a decision node', (0.5, 0.1), (0.1, 0.5), decisionNode)\n",
    "#    plotNode('a leaf node', (0.8, 0.1), (0.3, 0.8), leafNode)\n",
    "#    plt.show()\n",
    "\n",
    "mytree = retrieveTree(0)\n",
    "print('muytree:',mytree)\n",
    "#getNumLeafs(mytree)\n",
    "createPlot(mytree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "预剪枝是指在决策树生成过程中，对每个结点在划分之前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶节点\n",
    "后剪枝则是从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该节点对应的子树替换为叶结点能带来决策树泛化能力提升，则将子树替换为叶结点\n",
    "如何判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T07:20:33.433619Z",
     "start_time": "2018-07-19T07:20:33.429337Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=(6/17)\n",
    "b=(5/17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T07:21:12.896093Z",
     "start_time": "2018-07-19T07:21:12.886555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5798634010685344"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IV = -(a*log(a,2)+a*log(a,2)+b*log(b,2))\n",
    "IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T07:08:15.304655Z",
     "start_time": "2018-07-19T07:08:15.290343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9709505944546688"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IV = -(0.*log(0.5,2) + 0.5*log(0.5,2) + 0.4*log(0.4,2) + 0.6*log(0.6,2)) \n",
    "IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.决策树的分类函数"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "依靠训练数据构造了决策树之后，可以将它用于实际数据的分类\n",
    "在执行数据分类时，需要决策树及用于构造树的标签向量\n",
    "程序比较测试数据与决策树上的数值，递归执行该过程直到进入叶子结点\n",
    "将测试数据定义为叶子节点所属的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:19:51.540345Z",
     "start_time": "2018-07-18T06:19:51.531940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#函数retrieveTree输出预先存储的树信息\n",
    "#避免每次测试代码时都要从数据中创建树的麻烦\n",
    "def retrieveTree(i):\n",
    "    listOfTrees = [{'no surfacing':{0:'no',1:{'flippers':\\\n",
    "                                              {0:'no',1:'yes'}}}},\n",
    "                   {'no surfacing':{0:'no',1:{'flippers':\\\n",
    "                    {0:{'head':{0:'no',1:'yes'}},1:'no'}}}}\n",
    "                   ]\n",
    "    return listOfTrees[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:27:23.641377Z",
     "start_time": "2018-07-18T06:27:23.626223Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#函数retrieveTree输出预先存储的树信息\n",
    "#避免每次测试代码时都要从数据中创建树的麻烦\n",
    "\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    classLabel = ''\n",
    "    firstStr = list(inputTree.keys())[0] # 找到输入树当中键值[0]位置的值给firstStr#print('firstStr:', firstStr)\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__ == 'dict':\n",
    "                classLabel = classify(secondDict[key], featLabels, testVec)\n",
    "            else:\n",
    "                classLabel =secondDict[key]\n",
    "    \n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:27:24.624901Z",
     "start_time": "2018-07-18T06:27:24.609233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myTree: {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
      "firstStr: no surfing \n",
      "firstStr: flippers\n",
      "[1,0] is : no\n",
      "firstStr: no surfing \n",
      "firstStr: flippers\n",
      "[1,1] is: yes\n"
     ]
    }
   ],
   "source": [
    "myDat,labels = createDataSet()\n",
    "myTree = retrieveTree(0)\n",
    "print('myTree:', myTree)\n",
    "\n",
    "classlabel_1 = classify(mytree, labels, [1, 0])\n",
    "print ('[1,0] is :', classlabel_1)\n",
    "classlabel_2 = classify(mytree, labels, [1, 1])\n",
    "print ('[1,1] is:', classlabel_2)\n",
    "\n",
    "\"\"\"\n",
    "ValueError: 'no surfacing' is not in list\n",
    "主要原因是我先运行 mytree=createtree(data1,labels1)函数，\n",
    "而createtree函数在运行过程中回删除标签中已经用过的值，所以导致之后labels不完整，解决方法是再新建一个即可。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.树的存储和读取"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "存储与读取决策树主要是用到了pickle模块，具体我也没有细细的去深究pickle模块，具体可以参考http://www.php.cn/python-tutorials-372984.html。\n",
    "\n",
    "运行过程中报错如下：\n",
    "\n",
    "fr=open(filename)\n",
    "return pickle.load(fr)\n",
    "但是报错UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position 0: illegal multibyte sequence\n",
    "这是因为早期的pickle代码是二进制的pickle（除了最早的版本外）是二进制格式的，所以你应该带 'rb' 标志打开文件。\n",
    "改成\n",
    "def grabtree(filename):\n",
    "import pickle\n",
    "fr=open(filename,'rb')\n",
    "return pickle.load(fr)即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:47:58.429919Z",
     "start_time": "2018-07-18T06:47:58.417425Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#生成决策树的存储\n",
    "def storeTree(inputTree, filename):\n",
    "    import pickle\n",
    "    fw = open(filename, 'wb')\n",
    "    pickle.dump(inputTree, fw)\n",
    "    fw.close()\n",
    "\n",
    "def grabTree(filename):\n",
    "    import pickle\n",
    "    fr = open(filename, 'rb')\n",
    "    return pickle.load(fr)\n",
    "\"\"\"\n",
    "错误原因：pickle模块存储的是二进制字节码，需要以二进制的方式进行读写\n",
    "1. 报错一：TypeError: write() argument must be str, not bytes\n",
    "2. 报错二：UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
    "\n",
    "http://www.cnblogs.com/huiAlex/p/8855810.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:47:59.082057Z",
     "start_time": "2018-07-18T06:47:59.073747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no surfing ': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "storeTree(mytree, 'classifierstorage.txt')\n",
    "print(grabTree('classifierstorage.txt')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "决策树学习基本算法\n",
    "\n",
    "输入：训练集 D = {(x1,y1),(x2,y2)````(xm,ym)};\n",
    "     属性集 A = {a1, a2,`````,ad}.\n",
    "过程：函数TreeGenerate(D,A)\n",
    "1.生产节点node；\n",
    "2.if D中样本全属于同一类别C then\n",
    "3.   将node标记为C类叶节点；return\n",
    "4.end if\n",
    "5.if A=null OR D中样本在A上取值相同 then\n",
    "6.   将node标记为叶节点，其类别标记为D中样本数最多的类；then\n",
    "7.end if\n",
    "8.从A中选择最优划分属性a*；\n",
    "9.for a*的每一个值av* do\n",
    "10.   为node生成一个分之；令Dv表示D中在a*上取值为av*的样本子集\n",
    "11.   if Dv为空 then\n",
    "12.      将分支结点标记为叶结点，其类别标记为D中样本最多的类；return\n",
    "13.   else\n",
    "14.      以 TreeGenerate(Dv, A\\{a*})为分支结点\n",
    "15.   end if\n",
    "16.end if\n",
    "输出：以node为根结点的一棵决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T04:20:59.485927Z",
     "start_time": "2018-07-17T04:20:59.481146Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 计算给定数据集的香农熵 P36"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.计算数据集中实例的总数\n",
    "2.创建一个数据字典，它的键值是最后一列的数值\n",
    "3.如果当前键值不存在，则扩展字典并将当前键值加入字典。\n",
    "每个键值都记录了当前类别出现的次数\n",
    "4.使用所有标签的发生频率计算类别出现的概率。用这个概率计算香农熵，统计所有类别标签发生的次数\n",
    "\n",
    "熵越高，则混合的数据也越多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T05:51:06.335023Z",
     "start_time": "2018-07-17T05:51:06.290555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n"
     ]
    }
   ],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet) # 列表元素个数\n",
    "    labelCounts = {}# 创建了一个数据字典\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]#数据字典的键值是最后一列的数值\n",
    "        if currentLabel not in labelCounts.keys(): #字典.keys() 输出所有键\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "        #print(labelCounts)\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key]) / numEntries\n",
    "        shannonEnt -= prob*log(prob,2)\n",
    "    return shannonEnt\n",
    "        #print(labelCounts[key],numEntries)\n",
    "        #prob = float(labelCounts[key]) / numEntries\n",
    "        #print(prob)\n",
    "\n",
    "    \n",
    "    \n",
    "def createDataSet():\n",
    "    dataSet  = [[1, 1, 'yes'],\n",
    "                     [1, 1, 'yes'],\n",
    "                     [1, 0, 'no'],\n",
    "                     [0, 1, 'no'],\n",
    "                     [0, 1, 'no']]\n",
    "\n",
    "    labels = [ 'no surfcaing', 'flippers' ]\n",
    "    return dataSet, labels\n",
    "\n",
    "if __name__ == '__main__': #直接运行decision_tree,这个main函数会运行，如果是import decision_tree，main函数不运行\n",
    "    myDat, labels = createDataSet()\n",
    "    \n",
    "    #myDat[0][-1] = 'maybe'\n",
    " \n",
    "    \n",
    "    print(myDat)\n",
    "    #print(calcShannonEnt(myDat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3-2 按照给定特征划分数据集 P37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "分类算法需要测量信息熵，还需要划分数据集，度量划分数据集的熵，以便判断当前是否正确地划分了数据集\n",
    "将对每个特征划分数据集的结果计算一次信息熵\n",
    "然后判断按照哪个特征划分数据集是最好的划分方式\n",
    "\n",
    "代码使用了三个输入参数：待划分的数据集、划分数据集的特征、需要返回的特征的值\n",
    "因为该函数代码在同一数据集上被调用多次，为了不修改原始数据集，创建一个新的列表对象\n",
    "\n",
    "数据集这个列表中的各个元素也是列表，要遍历数据集中的每个元素，一旦发现符合要求的值，则将其添加到新创建的列表中\n",
    "在if语句中，程序将符合特征的数据抽取出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T06:00:37.161482Z",
     "start_time": "2018-07-17T06:00:37.148109Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            #print(\"featVec[axis]\",featVec[axis])\n",
    "            reduceFeatVec = featVec[:axis]\n",
    "            #print(\"reduceFeatVec\",reduceFeatVec)\n",
    "            reduceFeatVec.extend(featVec[axis+1:])\n",
    "            #print(\"reduceFeatVec\",reduceFeatVec)\n",
    "            retDataSet.append(reduceFeatVec)\n",
    "           #print(retDataSet)\n",
    "    return retDataSet\n",
    "#myDat \n",
    "#splitDataSet(myDat, 1, 0)\n",
    "#print(splitDataSet(myDat, 1, 0))\n",
    "#print(splitDataSet(myDat, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T04:21:07.391874Z",
     "start_time": "2018-07-17T04:21:07.370795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, [4, 5, 6], 4, 5, 6]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "a.append(b)#列表得到了第四个元素，而且第四个元素也是一个list\n",
    "a\n",
    "a.extend(b)#得到了一个包含a 和 b 所有元素的列表\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3 选择最好的数据集划分方式"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chooseBestFeatureToSplit()该函数实现选取特征，划分数据集，计算得出最好的划分数据集的特征\n",
    "使用了calcShannonEnt() splitDataSet()\n",
    "该函数中的数据需要满足一定的要求：\n",
    "1.数据必须是一种由列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度；\n",
    "2.数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T04:21:10.061864Z",
     "start_time": "2018-07-17T04:21:10.053488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T05:51:14.910636Z",
     "start_time": "2018-07-17T05:51:14.870509Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    #print(dataSet[0],len(dataSet[0]),numFeatures)  out：[1, 1, 'yes'] 3 2 \n",
    "    bestEntropy = calcShannonEnt(dataSet)\n",
    "    #print(bestEntropy)  out:0.9709505944546686\n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        #print (i ) out: 0 1 \n",
    "        featList = [example[i] for example in dataSet]\n",
    "        \"\"\"\n",
    "        example[i] for example in dataSet,for example in dataSet是取行，myDat共有5行，\n",
    "        example[0] for example in dataSet每次取每一行的【0】值，相当于取列\"\"\"\n",
    "        #print(featList) #out:[1, 1, 1, 0, 0]  [1, 1, 0, 1, 1]\n",
    "        uniqueVals = set(featList)\n",
    "        #创建唯一的分类标签的列表   print(uniqueVals) out:{0, 1}{0, 1} 取出每个类别的属性值\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value )\n",
    "            \"\"\"\n",
    "            print(subDataSet)\n",
    "            \n",
    "            [[1, 'no'], [1, 'no']]\n",
    "            [[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
    "            \n",
    "            [[1, 'no']]\n",
    "            [[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]\n",
    "            \"\"\"\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "            \"\"\"\n",
    "            print(i,newEntropy)\n",
    "            0 0.0\n",
    "            0 0.5509775004326937\n",
    "            \n",
    "            1 0.0\n",
    "            1 0.8\n",
    "            \"\"\"\n",
    "        infoGain = bestEntropy - newEntropy\n",
    "        \"\"\"\n",
    "        print(i,infoGain)\n",
    "        \n",
    "        0 0.4199730940219749\n",
    "        1 0.17095059445466854\"\"\"\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i \n",
    "            #print(bestInfoGain)0.4199730940219749\n",
    "    return bestFeature\n",
    "\n",
    "#chooseBestFeatureToSplit(myDat)\n",
    "#myDat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "example[i] for example in dataSet\n",
    "\n",
    "\n",
    "这个方式是一个列表生成式。[i for i in range(10)],会生成一个[0,1,2,3,4,5,6,7,8,9]的列表。这里面，dataset是一个可迭代的对象，可能是列表，元祖或者自定义的可迭代的对象。这个迭代器里面，每个元素是一个字典，或者list。然后通过i去取出expamle中，key为i,或者第i个元素，通过这些元素，组成一个新的列表\n",
    "\n",
    "语句featList = [example[i] for example in dataSet]作用为： \n",
    "将dataSet中的数据按行依次放入example中，然后取得example中的example[i]元素，放入列表featList中\n",
    "\n",
    "语句classList = [example[-1] for example in dataSet]作用为： \n",
    "将dataSet中的数据按行依次放入example中，然后取得example中的example[-1]元素，放入列表classList中\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 递归构建决策树"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "递归结束的条件：程序遍历所有划分数据集的属性，或者每个分之下的所有实例都具有相同的分类。\n",
    "如果所有实例具有相同的分类，则得到的是一个叶子结点或者终止块。任何到达叶子节点的数据必然属于叶子节点的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T05:51:16.792110Z",
     "start_time": "2018-07-17T05:51:16.781493Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    classList = {}\n",
    "    #创建classList中唯一值的数据字典，字典对象存储了classList中每个类标签出现的频率\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(),\\\n",
    "                              key = operator.itemgetter(1), reverse = True)\n",
    "    #利用operator操作键值排序字典，并返回出现次数最多的分类名称\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4 创建树的函数代码 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "使用两个输入参数：数据集和标签列表\n",
    "标签列表包含了数据集中所有特征的标签，算法本身并不需要这个变量，但是为了给出数据明确的含义，将它作为一个输入参数提供\n",
    "该函数中的数据需要满足一定的要求：\n",
    "1.数据必须是一种由列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度；\n",
    "2.数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签\n",
    "\n",
    "\n",
    "1.创建了名为classList的列表变量，其中包含了数据集的所有类标签.递归函数第一个停止条件是所有的类标签完全相同，则返回该类标签\n",
    "2.递归函数的第二个停止条件是使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组\n",
    "3.声明字典类型存储了树的所有信息，当前数据集选取的最好特征存储在变量bestFeat中，得到列表包含的所有属性值\n",
    "4.遍历当前选择特征包含的所有属性值，每个数据集划分上递归调用函数creatTree()，得到返回值将被插入到字典变量myTree中\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T05:51:52.370216Z",
     "start_time": "2018-07-17T05:51:52.329279Z"
    }
   },
   "source": [
    "def createTree(dataSet, labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{ }}\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]#复制了类标签，将其存储在新列表变量subLabels中\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet\\\n",
    "                                                 (dataSet, bestFeat, value),subLabels)\n",
    "    return myTree\n",
    "\n",
    "\n",
    "myTree = createTree(myDat, labels)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T06:38:21.020808Z",
     "start_time": "2018-07-17T06:38:21.007255Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import mpl\n",
    "\n",
    "mpl.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体\n",
    "mpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T07:17:18.901877Z",
     "start_time": "2018-07-17T07:17:18.239359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt  = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key]) / numEntries\n",
    "        shannonEnt -= prob * log(prob , 2)\n",
    "    return shannonEnt\n",
    "\n",
    "def createDataSet():\n",
    "    dataSet  = [[1, 1, 'yes'],\n",
    "                     [1, 1, 'yes'],\n",
    "                     [1, 0, 'no'],\n",
    "                     [0, 1, 'no'],\n",
    "                     [0, 1, 'no']]\n",
    "\n",
    "    labels = [ 'no surfcaing', 'flippers' ]\n",
    "    return dataSet, labels\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reduceFeatVec = featVec[:axis]\n",
    "            reduceFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reduceFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    bestEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0;\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = bestEntropy - newEntropy\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature\n",
    "\n",
    "\n",
    "import operator\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    classList = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(),\\\n",
    "                              key = operator.itemgetter(1), reverse = True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "def createTree(dataSet, labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{ }}\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet\\\n",
    "                                                 (dataSet, bestFeat, value),subLabels)\n",
    "    return myTree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "decisionNode = dict(boxstyle = 'sawtooth', fc = \"0.8\")\n",
    "leafNode = dict(boxstyle =\"round4\", fc = \"0.8\")\n",
    "arrow_args = dict(arrowstyle = \"<-\")\n",
    "\"\"\"定义文本框和箭头格式\"\"\"\n",
    "def plotNode(nodeTxt, centerPt, parentPt, nodeType):\n",
    "    createPlot.ax1.annotate(nodeTxt, xy=parentPt,\\\n",
    "                           xycoords = 'axes fraction', \\\n",
    "                           xytext = centerPt, textcoords = 'axes fraction',\\\n",
    "                           va=\"center\", ha=\"center\", bbox=nodeType, arrowprops=arrow_args)\n",
    "def createPlot():\n",
    "    fig = plt.figure(1, facecolor='white')\n",
    "    fig.clf()\n",
    "    createPlot.ax1 = plt.subplot(111, frameon=False)\n",
    "    plotNode(U'决策节点', (0.5, 0.1), (0.1, 0.5), decisionNode)\n",
    "    plotNode(U'叶节点', (0.8, 0.1), (0.3, 0.8), leafNode)\n",
    "    plt.show()\n",
    "\n",
    "#得到叶子节点的数目\n",
    "def getNumLeafs(myTree):\n",
    "    numLeafs = 0\n",
    "    firstStr = list(myTree.keys())[0]\n",
    "    \"\"\"\n",
    "    会产生错误：TypeError: 'dict_keys' object does not support indexing\n",
    "    这是由于python3改变了dict.keys,返回的是dict_keys对象,支持iterable 但不支持indexable，我们可以将其明确的转化成list：\n",
    "    \"\"\"\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__=='dict':#这里说的只是二叉树吧？？应该？\n",
    "            numLeafs += getNumLeafs(secondDict[key])\n",
    "        else:    numLeafs += 1\n",
    "    return numLeafs\n",
    " \n",
    "#树的层数\n",
    "def getTreeDepth(myTree):\n",
    "    maxDepth = 0\n",
    "    firstStr = list(myTree.keys())[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__ == 'dict':#一层只有一个dict\n",
    "            thisDepth = 1 + getTreeDepth(secondDict[key])\n",
    "            #print(123)\n",
    "        else:\n",
    "            thisDepth = 1\n",
    "            #print(456)\n",
    "        if thisDepth > maxDepth: maxDepth = thisDepth\n",
    "    return maxDepth\n",
    "\n",
    "\n",
    "def retrieveTree(i):\n",
    "    listOfTrees = [{'no surfcaing': {0: 'no', 1: {'flippers': \\\n",
    "                                                 {0: 'no', 1: 'yes'}}}},\n",
    "                  {'no surfcaing': {0: 'no', 1: {'flippers': \\\n",
    "                                                 {0: {'head': {0:'no', 1: 'yes'}}, 1:'no'}}}}\n",
    "                  ]\n",
    "    return listOfTrees[i]\n",
    "\n",
    "\n",
    "if __name__ == '__main__': #直接运行decision_tree,这个main函数会运行，如果是import decision_tree，main函数不运行\n",
    "    myDat, labels = createDataSet()\n",
    "    #print(myDat,labels)\n",
    "    #print(calcShannonEnt(myDat))\n",
    "    #myTree = createTree(myDat,labels)\n",
    "    #myTree\n",
    "    #createPlot()\n",
    "    myTree = retrieveTree(0)\n",
    "    print(getNumLeafs(myTree))\n",
    "    print(getTreeDepth(myTree))   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T07:14:54.288178Z",
     "start_time": "2018-07-17T07:14:54.284394Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mytree = retrieveTree(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T07:15:50.461543Z",
     "start_time": "2018-07-17T07:15:50.453951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no surfcaing'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mytree.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:06:57.259546Z",
     "start_time": "2018-07-07T23:06:56.173028Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:07:15.534319Z",
     "start_time": "2018-07-07T23:07:15.518353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = 4, 5, 6\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:11:33.826133Z",
     "start_time": "2018-07-07T23:11:33.809533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 5, 6), (7, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_tup = (4, 5, 6),(7, 8)\n",
    "nested_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:14:17.195109Z",
     "start_time": "2018-07-07T23:14:17.185437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([4, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:15:29.826354Z",
     "start_time": "2018-07-07T23:15:29.815456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s', 't', 'r', 'i', 'n', 'g')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = tuple(\"string\")\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:20:58.435943Z",
     "start_time": "2018-07-07T23:20:58.415784Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bc4af7624d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "tup = tuple(['foo', [1,2], True])\n",
    "tup[2] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:22:22.916036Z",
     "start_time": "2018-07-07T23:22:22.905068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('foo', [1, 2, 3], True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup[1].append(3)\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:23:59.528614Z",
     "start_time": "2018-07-07T23:23:59.517813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, None, 'foo', 6, 0, 'bar')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4, None, 'foo')+(6, 0)+('bar',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:26:19.209393Z",
     "start_time": "2018-07-07T23:26:19.199962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = (4, 5, 6)\n",
    "a, b, c = tup\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:27:53.618712Z",
     "start_time": "2018-07-07T23:27:53.607584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = 4, 5, (6, 7)\n",
    "a, b, (c, d) = tup\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:30:38.972801Z",
     "start_time": "2018-07-07T23:30:38.960044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [(1, 2, 3),(4, 5, 6),(7, 8, 9)]\n",
    "for a, b, c in seq:\n",
    "    pass\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:32:07.565076Z",
     "start_time": "2018-07-07T23:32:07.558979Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = (1, 2, 2, 2, 2, 3, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:32:13.530796Z",
     "start_time": "2018-07-07T23:32:13.521475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.count(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:40:39.779637Z",
     "start_time": "2018-07-07T23:40:39.765148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 7, None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list = [2, 3, 7, None]\n",
    "a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:53:54.879688Z",
     "start_time": "2018-07-07T23:53:54.870360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar', 'baz']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = ('foo', 'bar', 'baz')\n",
    "b_list =list(tup)\n",
    "b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:53:56.601051Z",
     "start_time": "2018-07-07T23:53:56.590555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'peekaboo', 'baz']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list[1] = 'peekaboo'\n",
    "b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:53:58.535221Z",
     "start_time": "2018-07-07T23:53:58.524594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'peekaboo', 'baz', 'dwarf']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list.append('dwarf')\n",
    "b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:53:59.811929Z",
     "start_time": "2018-07-07T23:53:59.798322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'red', 'peekaboo', 'baz', 'dwarf']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list.insert(1, 'red')\n",
    "b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:54:02.158776Z",
     "start_time": "2018-07-07T23:54:02.146832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'peekaboo'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list.pop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:54:03.094470Z",
     "start_time": "2018-07-07T23:54:03.080847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'red', 'baz', 'dwarf']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:54:05.636540Z",
     "start_time": "2018-07-07T23:54:05.625372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'baz', 'dwarf', 'foo']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list.append('foo')\n",
    "b_list.remove('foo')\n",
    "b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T23:58:10.712735Z",
     "start_time": "2018-07-07T23:58:10.701003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dwarf' in b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T04:52:36.407149Z",
     "start_time": "2018-07-08T04:52:36.273740Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.apply??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T04:52:56.871499Z",
     "start_time": "2018-07-08T04:52:56.844224Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series.map??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
